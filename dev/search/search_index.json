{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"NWM Coastal","text":"<p>A Python package for running SCHISM and SFINCS coastal model calibration workflows on HPC clusters with Singularity containers and SLURM job scheduling.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Multi-Model Support: SCHISM (multi-node MPI) and SFINCS (single-node OpenMP) via a     polymorphic <code>ModelConfig</code> architecture</li> <li>YAML Configuration: Simple, human-readable configuration files with variable     interpolation</li> <li>SLURM Integration: Automatic job script generation and submission</li> <li>Data Download: Automated download of NWM and STOFS boundary data</li> <li>Multiple Domains: Support for Hawaii, Puerto Rico/Virgin Islands, Atlantic/Gulf,     and Pacific</li> <li>Boundary Conditions: TPXO tidal model and STOFS water level support</li> <li>Workflow Control: Run complete workflows or specific stages</li> <li>Configuration Inheritance: Share common settings across multiple runs</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code># config.yaml - minimal SCHISM configuration\nslurm:\n  job_name: my_schism_run\n  user: your_username\n\nsimulation:\n  start_date: 2021-06-11\n  duration_hours: 24\n  coastal_domain: hawaii\n  meteo_source: nwm_ana\n\nboundary:\n  source: stofs\n</code></pre> <pre><code># Submit and monitor the job\ncoastal-calibration submit config.yaml --interactive\n</code></pre>"},{"location":"#supported-models","title":"Supported Models","text":"Model Status Description SCHISM Supported Semi-implicit Cross-scale Hydroscience Integrated System Model SFINCS Supported Super-Fast INundation of CoastS"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install coastal-calibration\n</code></pre> <p>See the Installation Guide for detailed instructions.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the BSD-2-Clause License. See LICENSE for details.</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python &gt;= 3.11</li> <li>Access to an HPC cluster with SLURM and Singularity</li> <li>NFS mount point (default: <code>/ngen-test</code>)</li> <li>Singularity image with SCHISM and/or SFINCS and dependencies pre-compiled</li> </ul> <p>Model Executables</p> <p>This package orchestrates SCHISM and SFINCS workflows on HPC clusters where the models are already compiled and available (typically inside a Singularity container). You do not need to install SCHISM or SFINCS locally to use this package for job submission.</p>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install coastal-calibration\n</code></pre> <p>This installs the core package with CLI and workflow orchestration capabilities.</p>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":"<p>For development or to get the latest features, install from source:</p> <pre><code>git clone https://github.com/NGWPC/nwm-coastal\ncd nwm-coastal\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#development-installation-with-pixi","title":"Development Installation with Pixi","text":"<p>For development, we recommend using Pixi for environment management:</p> <pre><code># Install Pixi (Linux/macOS)\ncurl -fsSL https://pixi.sh/install.sh | sh\n</code></pre> <p>Restart Terminal</p> <p>After installing Pixi, restart your terminal or run <code>source ~/.bashrc</code> (or <code>source ~/.zshrc</code> for Zsh) to make the <code>pixi</code> command available.</p> <pre><code># Clone and install\ngit clone https://github.com/NGWPC/nwm-coastal\ncd nwm-coastal\npixi install -e dev\n</code></pre>"},{"location":"getting-started/installation/#available-environments","title":"Available Environments","text":"Environment Description Command <code>dev</code> Development with all tools <code>pixi r -e dev &lt;cmd&gt;</code> <code>test311</code> Testing with Python 3.11 <code>pixi r -e test311 test</code> <code>test314</code> Testing with Python 3.14 <code>pixi r -e test314 test</code> <code>schism</code> Local development with SCHISM I/O libraries <code>pixi r -e schism &lt;cmd&gt;</code> <code>sfincs</code> Local development with HydroMT-SFINCS <code>pixi r -e sfincs &lt;cmd&gt;</code> <code>typecheck</code> Type checking with Pyright <code>pixi r -e typecheck typecheck</code> <code>lint</code> Linting with pre-commit <code>pixi r lint</code> <code>docs</code> Documentation building <code>pixi r -e docs docs-serve</code>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>Optional dependencies are available for local development purposes only. They are useful for:</p> <ul> <li>Reading and analyzing model output files</li> <li>Debugging and testing workflow components locally</li> <li>Building SFINCS models with HydroMT</li> </ul> <p>Not Required for Cluster Execution</p> <p>These optional dependencies are not required to submit and run jobs on the cluster. The actual SCHISM and SFINCS executables must be pre-compiled and available on the HPC cluster (inside the Singularity container).</p> <pre><code># SCHISM I/O dependencies (netCDF, numpy, etc.) - for local development\npip install coastal-calibration[schism]\n\n# SFINCS/HydroMT dependencies - for local model building and analysis\npip install coastal-calibration[sfincs]\n\n# Development dependencies (Jupyter, etc.)\npip install coastal-calibration[dev]\n\n# Documentation dependencies\npip install coastal-calibration[docs]\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>After installation, verify by running:</p> <pre><code>coastal-calibration --help\n</code></pre> <p>You should see the CLI help output with available commands:</p> <pre><code>Usage: coastal-calibration [OPTIONS] COMMAND [ARGS]...\n\n  NWM Coastal: Coastal model workflow on HPC clusters.\n\nCommands:\n  init      Generate a new configuration file.\n  validate  Validate a configuration file.\n  submit    Submit workflow as a SLURM job.\n  run       Run workflow directly.\n  stages    List available workflow stages.\n</code></pre>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>This guide walks you through running your first coastal simulation using the <code>coastal-calibration</code> CLI.</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li><code>coastal-calibration</code> installed (see Installation)</li> <li>Access to an HPC cluster with SLURM</li> <li>The Singularity image at <code>/ngencerf-app/singularity/ngen-coastal.sif</code></li> <li>Access to the <code>/ngen-test</code> NFS mount</li> </ul>"},{"location":"getting-started/quickstart/#schism-quick-start","title":"SCHISM Quick Start","text":""},{"location":"getting-started/quickstart/#step-1-generate-a-configuration-file","title":"Step 1: Generate a Configuration File","text":"<p>Create a new configuration file for your simulation:</p> <pre><code>coastal-calibration init config.yaml --domain hawaii\n</code></pre> <p>This generates a template configuration file with sensible defaults.</p>"},{"location":"getting-started/quickstart/#step-2-edit-the-configuration","title":"Step 2: Edit the Configuration","text":"<p>Open <code>config.yaml</code> and set your SLURM username:</p> <pre><code>slurm:\n  job_name: my_schism_run\n  user: your_username  # Replace with your SLURM username\n\nsimulation:\n  start_date: 2021-06-11\n  duration_hours: 24\n  coastal_domain: hawaii\n  meteo_source: nwm_ana\n\nboundary:\n  source: stofs\n</code></pre> <p>Minimal Configuration</p> <p>The configuration above is all you need! Paths are automatically generated based on your username, domain, and data sources.</p>"},{"location":"getting-started/quickstart/#step-3-validate-the-configuration","title":"Step 3: Validate the Configuration","text":"<p>Before submitting, validate your configuration:</p> <pre><code>coastal-calibration validate config.yaml\n</code></pre> <p>This checks for:</p> <ul> <li>Required fields</li> <li>Valid date ranges for data sources</li> <li>File and directory existence</li> <li>SLURM configuration validity</li> </ul>"},{"location":"getting-started/quickstart/#step-4-submit-the-job","title":"Step 4: Submit the Job","text":""},{"location":"getting-started/quickstart/#option-a-submit-and-return-immediately-default","title":"Option A: Submit and Return Immediately (Default)","text":"<pre><code>coastal-calibration submit config.yaml\n</code></pre> <p>This will:</p> <ol> <li>Download required NWM and STOFS data (on the login node)</li> <li>Generate SLURM job scripts</li> <li>Submit the job and return immediately</li> </ol> <pre><code>INFO  Running download stage on login node...\nINFO  meteo/nwm_ana: 4/4 [OK]\nINFO  hydro/nwm: 16/16 [OK]\nINFO  coastal/stofs: 1/1 [OK]\nINFO  Total: 21/21 (failed: 0)\nINFO  Download stage completed\nINFO  Job 167 submitted.\nINFO  Check job status with: squeue -j 167\n</code></pre>"},{"location":"getting-started/quickstart/#option-b-submit-and-wait-for-completion","title":"Option B: Submit and Wait for Completion","text":"<p>Use the <code>--interactive</code> flag to monitor the job until it completes:</p> <pre><code>coastal-calibration submit config.yaml --interactive\n</code></pre>"},{"location":"getting-started/quickstart/#step-5-check-results","title":"Step 5: Check Results","text":"<p>After the job completes, find your outputs in the work directory:</p> <pre><code>ls /ngen-test/coastal/your_username/schism_hawaii_stofs_nwm_ana/schism_2021-06-11/\n</code></pre>"},{"location":"getting-started/quickstart/#sfincs-quick-start","title":"SFINCS Quick Start","text":""},{"location":"getting-started/quickstart/#step-1-generate-a-sfincs-configuration","title":"Step 1: Generate a SFINCS Configuration","text":"<pre><code>coastal-calibration init sfincs_config.yaml --domain atlgulf --model sfincs\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-edit-the-configuration_1","title":"Step 2: Edit the Configuration","text":"<p>Set your username and the path to a pre-built SFINCS model:</p> <pre><code>model: sfincs\n\nslurm:\n  job_name: my_sfincs_run\n  user: your_username\n\nsimulation:\n  start_date: 2025-06-01\n  duration_hours: 168\n  coastal_domain: atlgulf\n  meteo_source: nwm_ana\n\nboundary:\n  source: stofs\n\nmodel_config:\n  prebuilt_dir: /path/to/prebuilt/sfincs/model\n</code></pre>"},{"location":"getting-started/quickstart/#step-3-validate-and-submit","title":"Step 3: Validate and Submit","text":"<pre><code>coastal-calibration validate sfincs_config.yaml\ncoastal-calibration submit sfincs_config.yaml --interactive\n</code></pre>"},{"location":"getting-started/quickstart/#using-the-python-api","title":"Using the Python API","text":"<p>You can also run workflows programmatically:</p> <pre><code>from coastal_calibration import CoastalCalibConfig, CoastalCalibRunner\n\n# Load configuration\nconfig = CoastalCalibConfig.from_yaml(\"config.yaml\")\n\n# Create runner and submit\nrunner = CoastalCalibRunner(config)\nresult = runner.submit(wait=True)\n\nif result.success:\n    print(f\"Job completed in {result.duration_seconds:.1f}s\")\nelse:\n    print(f\"Job failed: {result.errors}\")\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Configuration Options</li> <li>Explore Workflow Stages</li> <li>See the CLI Reference</li> </ul>"},{"location":"reference/api/","title":"API Reference","text":"<p>This page provides detailed documentation for the NWM Coastal Python API.</p>"},{"location":"reference/api/#configuration-classes","title":"Configuration Classes","text":""},{"location":"reference/api/#coastalcalibconfig","title":"CoastalCalibConfig","text":""},{"location":"reference/api/#coastal_calibration.config.schema.CoastalCalibConfig","title":"CoastalCalibConfig  <code>dataclass</code>","text":"<pre><code>CoastalCalibConfig(\n    slurm,\n    simulation,\n    boundary,\n    paths,\n    model_config,\n    monitoring=MonitoringConfig(),\n    download=DownloadConfig(),\n    _base_config=None,\n)\n</code></pre> <p>Complete coastal calibration workflow configuration.</p> <p>Supports both SCHISM and SFINCS models via the polymorphic :attr:<code>model_config</code> field.  The concrete type is selected by the <code>model</code> key in the YAML file and resolved through :data:<code>MODEL_REGISTRY</code>.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.CoastalCalibConfig.model","title":"model  <code>property</code>","text":"<pre><code>model\n</code></pre> <p>Model identifier string (convenience accessor).</p>"},{"location":"reference/api/#coastal_calibration.config.schema.CoastalCalibConfig.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(config_path)\n</code></pre> <p>Load configuration from YAML file with optional inheritance.</p> <p>Supports variable interpolation using ${section.key} syntax. Variables are resolved from other config values, e.g.:</p> <ul> <li><code>${slurm.user}</code> -&gt; value of <code>slurm.user</code></li> <li><code>${simulation.coastal_domain}</code> -&gt; value of <code>simulation.coastal_domain</code></li> <li><code>${model}</code> -&gt; the model type string (<code>\"schism\"</code> or <code>\"sfincs\"</code>)</li> </ul> PARAMETER DESCRIPTION <code>config_path</code> <p>Path to YAML configuration file.</p> <p> TYPE: <code>Path or str</code> </p> RETURNS DESCRIPTION <code>CoastalCalibConfig</code> <p>Loaded configuration.</p> RAISES DESCRIPTION <code>FileNotFoundError</code> <p>If the configuration file does not exist.</p> <code>YAMLError</code> <p>If the YAML file is malformed.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>@classmethod\ndef from_yaml(cls, config_path: Path | str) -&gt; CoastalCalibConfig:\n    \"\"\"Load configuration from YAML file with optional inheritance.\n\n    Supports variable interpolation using ${section.key} syntax.\n    Variables are resolved from other config values, e.g.:\n\n    - ``${slurm.user}`` -&gt; value of ``slurm.user``\n    - ``${simulation.coastal_domain}`` -&gt; value of ``simulation.coastal_domain``\n    - ``${model}`` -&gt; the model type string (``\"schism\"`` or ``\"sfincs\"``)\n\n    Parameters\n    ----------\n    config_path : Path or str\n        Path to YAML configuration file.\n\n    Returns\n    -------\n    CoastalCalibConfig\n        Loaded configuration.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the configuration file does not exist.\n    yaml.YAMLError\n        If the YAML file is malformed.\n    \"\"\"\n    config_path = Path(config_path)\n    if not config_path.exists():\n        raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n\n    try:\n        data = yaml.safe_load(config_path.read_text())\n    except yaml.YAMLError as e:\n        raise yaml.YAMLError(f\"Invalid YAML in {config_path}: {e}\") from e\n\n    if data is None:\n        raise ValueError(f\"Configuration file is empty: {config_path}\")\n\n    base_config = None\n    if \"_base\" in data:\n        base_path = Path(data.pop(\"_base\"))\n        if not base_path.is_absolute():\n            base_path = config_path.parent / base_path\n        base_config = cls.from_yaml(base_path)\n        data = _deep_merge(base_config.to_dict(), data)\n\n    # Ensure model key has a default before interpolation\n    data.setdefault(\"model\", \"schism\")\n\n    # Inject default path templates if not provided (before interpolation)\n    if \"paths\" not in data:\n        data[\"paths\"] = {}\n    if \"work_dir\" not in data[\"paths\"]:\n        data[\"paths\"][\"work_dir\"] = DEFAULT_WORK_DIR_TEMPLATE\n    if \"raw_download_dir\" not in data[\"paths\"]:\n        data[\"paths\"][\"raw_download_dir\"] = DEFAULT_RAW_DOWNLOAD_DIR_TEMPLATE\n\n    # Interpolate variables after merging\n    data = _interpolate_config(data)\n\n    return cls._from_dict(data, base_config_path=config_path if base_config else None)\n</code></pre>"},{"location":"reference/api/#coastal_calibration.config.schema.CoastalCalibConfig.to_yaml","title":"to_yaml","text":"<pre><code>to_yaml(path)\n</code></pre> <p>Write configuration to YAML file.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to YAML output file. Parent directories will be created if they don't exist.</p> <p> TYPE: <code>Path or str</code> </p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>def to_yaml(self, path: Path | str) -&gt; None:\n    \"\"\"Write configuration to YAML file.\n\n    Parameters\n    ----------\n    path : Path or str\n        Path to YAML output file. Parent directories will be created\n        if they don't exist.\n    \"\"\"\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    path.write_text(yaml.dump(self.to_dict(), default_flow_style=False, sort_keys=False))\n</code></pre>"},{"location":"reference/api/#coastal_calibration.config.schema.CoastalCalibConfig.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Convert config to dictionary.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert config to dictionary.\"\"\"\n    return {\n        \"model\": self.model,\n        \"slurm\": {\n            \"job_name\": self.slurm.job_name,\n            \"partition\": self.slurm.partition,\n            \"time_limit\": self.slurm.time_limit,\n            \"account\": self.slurm.account,\n            \"qos\": self.slurm.qos,\n            \"user\": self.slurm.user,\n        },\n        \"simulation\": {\n            \"start_date\": self.simulation.start_date.isoformat(),\n            \"duration_hours\": self.simulation.duration_hours,\n            \"coastal_domain\": self.simulation.coastal_domain,\n            \"meteo_source\": self.simulation.meteo_source,\n            \"timestep_seconds\": self.simulation.timestep_seconds,\n        },\n        \"boundary\": {\n            \"source\": self.boundary.source,\n            \"stofs_file\": (str(self.boundary.stofs_file) if self.boundary.stofs_file else None),\n        },\n        \"paths\": {\n            \"work_dir\": str(self.paths.work_dir),\n            \"raw_download_dir\": (\n                str(self.paths.raw_download_dir) if self.paths.raw_download_dir else None\n            ),\n            \"nfs_mount\": str(self.paths.nfs_mount),\n            \"singularity_image\": str(self.paths.singularity_image),\n            \"ngen_app_dir\": str(self.paths.ngen_app_dir),\n            \"hot_start_file\": (\n                str(self.paths.hot_start_file) if self.paths.hot_start_file else None\n            ),\n            \"conda_env_name\": self.paths.conda_env_name,\n            \"parm_dir\": str(self.paths.parm_dir),\n        },\n        \"model_config\": self.model_config.to_dict(),\n        \"monitoring\": {\n            \"log_level\": self.monitoring.log_level,\n            \"log_file\": (str(self.monitoring.log_file) if self.monitoring.log_file else None),\n            \"enable_progress_tracking\": self.monitoring.enable_progress_tracking,\n            \"enable_timing\": self.monitoring.enable_timing,\n        },\n        \"download\": {\n            \"enabled\": self.download.enabled,\n            \"skip_existing\": self.download.skip_existing,\n            \"timeout\": self.download.timeout,\n            \"raise_on_error\": self.download.raise_on_error,\n            \"limit_per_host\": self.download.limit_per_host,\n        },\n    }\n</code></pre>"},{"location":"reference/api/#coastal_calibration.config.schema.CoastalCalibConfig.validate","title":"validate","text":"<pre><code>validate()\n</code></pre> <p>Validate configuration and return list of errors.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>def validate(self) -&gt; list[str]:\n    \"\"\"Validate configuration and return list of errors.\"\"\"\n    from coastal_calibration.downloader import validate_date_ranges\n\n    errors: list[str] = []\n\n    if self.simulation.duration_hours &lt;= 0:\n        errors.append(\"simulation.duration_hours must be positive\")\n\n    # Model-specific validation\n    errors.extend(self.model_config.validate(self))\n\n    # Shared boundary validation\n    errors.extend(self._validate_boundary_source())\n\n    # Date range validation\n    if self.download.enabled:\n        sim = self.simulation\n        start_time = sim.start_date\n        end_time = start_time + timedelta(hours=sim.duration_hours)\n        date_errors = validate_date_ranges(\n            start_time,\n            end_time,\n            sim.meteo_source,\n            self.boundary.source,\n            sim.coastal_domain,\n        )\n        errors.extend(date_errors)\n\n    return errors\n</code></pre>"},{"location":"reference/api/#slurmconfig","title":"SlurmConfig","text":""},{"location":"reference/api/#coastal_calibration.config.schema.SlurmConfig","title":"SlurmConfig  <code>dataclass</code>","text":"<pre><code>SlurmConfig(\n    job_name=\"coastal_calibration\",\n    partition=DEFAULT_SLURM_PARTITION,\n    time_limit=None,\n    account=None,\n    qos=None,\n    user=None,\n)\n</code></pre> <p>SLURM job scheduling configuration.</p> <p>Contains only parameters related to job scheduling (partition, account, time limits).  Compute resources (nodes, tasks) are model-specific and live on the concrete :class:<code>ModelConfig</code> subclasses.</p>"},{"location":"reference/api/#simulationconfig","title":"SimulationConfig","text":""},{"location":"reference/api/#coastal_calibration.config.schema.SimulationConfig","title":"SimulationConfig  <code>dataclass</code>","text":"<pre><code>SimulationConfig(\n    start_date,\n    duration_hours,\n    coastal_domain,\n    meteo_source,\n    timestep_seconds=3600,\n)\n</code></pre> <p>Simulation time and domain configuration.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.SimulationConfig.start_pdy","title":"start_pdy  <code>property</code>","text":"<pre><code>start_pdy\n</code></pre> <p>Return start date as YYYYMMDD string.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.SimulationConfig.start_cyc","title":"start_cyc  <code>property</code>","text":"<pre><code>start_cyc\n</code></pre> <p>Return start cycle (hour) as HH string.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.SimulationConfig.inland_domain","title":"inland_domain  <code>property</code>","text":"<pre><code>inland_domain\n</code></pre> <p>Inland domain directory name for this coastal domain.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.SimulationConfig.nwm_domain","title":"nwm_domain  <code>property</code>","text":"<pre><code>nwm_domain\n</code></pre> <p>NWM domain identifier for this coastal domain.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.SimulationConfig.geo_grid","title":"geo_grid  <code>property</code>","text":"<pre><code>geo_grid\n</code></pre> <p>Geogrid filename for this coastal domain.</p>"},{"location":"reference/api/#boundaryconfig","title":"BoundaryConfig","text":""},{"location":"reference/api/#coastal_calibration.config.schema.BoundaryConfig","title":"BoundaryConfig  <code>dataclass</code>","text":"<pre><code>BoundaryConfig(source='tpxo', stofs_file=None)\n</code></pre> <p>Boundary condition configuration.</p>"},{"location":"reference/api/#pathconfig","title":"PathConfig","text":""},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig","title":"PathConfig  <code>dataclass</code>","text":"<pre><code>PathConfig(\n    work_dir,\n    raw_download_dir=None,\n    nfs_mount=(lambda: DEFAULT_NFS_MOUNT)(),\n    singularity_image=(lambda: DEFAULT_SING_IMAGE_PATH)(),\n    ngen_app_dir=(lambda: DEFAULT_NGEN_APP_DIR)(),\n    hot_start_file=None,\n    conda_env_name=DEFAULT_CONDA_ENV_NAME,\n    parm_dir=(lambda: DEFAULT_PARM_DIR)(),\n)\n</code></pre> <p>Path configuration for data and executables.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.otps_dir","title":"otps_dir  <code>property</code>","text":"<pre><code>otps_dir\n</code></pre> <p>TPXO binary directory (inside Singularity container, not configurable).</p>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.tpxo_data_dir","title":"tpxo_data_dir  <code>property</code>","text":"<pre><code>tpxo_data_dir\n</code></pre> <p>TPXO tidal atlas data directory.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.nwm_version_dir","title":"nwm_version_dir  <code>property</code>","text":"<pre><code>nwm_version_dir\n</code></pre> <p>NWM version directory (ush, exec live here).</p>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.ush_nwm","title":"ush_nwm  <code>property</code>","text":"<pre><code>ush_nwm\n</code></pre> <p>USH scripts directory.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.exec_nwm","title":"exec_nwm  <code>property</code>","text":"<pre><code>exec_nwm\n</code></pre> <p>Executables directory.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.parm_nwm","title":"parm_nwm  <code>property</code>","text":"<pre><code>parm_nwm\n</code></pre> <p>Parameter files directory.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.conda_envs_path","title":"conda_envs_path  <code>property</code>","text":"<pre><code>conda_envs_path\n</code></pre> <p>Conda environments directory.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.download_dir","title":"download_dir  <code>property</code>","text":"<pre><code>download_dir\n</code></pre> <p>Effective download directory (fallback to work_dir/downloads).</p>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.meteo_dir","title":"meteo_dir","text":"<pre><code>meteo_dir(meteo_source)\n</code></pre> <p>Directory for meteorological data.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>def meteo_dir(self, meteo_source: str) -&gt; Path:\n    \"\"\"Directory for meteorological data.\"\"\"\n    return self.download_dir / self.METEO_SUBDIR / meteo_source\n</code></pre>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.streamflow_dir","title":"streamflow_dir","text":"<pre><code>streamflow_dir(meteo_source)\n</code></pre> <p>Directory for streamflow/hydro data.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>def streamflow_dir(self, meteo_source: str) -&gt; Path:\n    \"\"\"Directory for streamflow/hydro data.\"\"\"\n    if meteo_source == \"nwm_retro\":\n        return self.download_dir / self.STREAMFLOW_SUBDIR / \"nwm_retro\"\n    return self.download_dir / self.HYDRO_SUBDIR / \"nwm\"\n</code></pre>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.coastal_dir","title":"coastal_dir","text":"<pre><code>coastal_dir(coastal_source)\n</code></pre> <p>Directory for coastal boundary data.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>def coastal_dir(self, coastal_source: str) -&gt; Path:\n    \"\"\"Directory for coastal boundary data.\"\"\"\n    return self.download_dir / self.COASTAL_SUBDIR / coastal_source\n</code></pre>"},{"location":"reference/api/#coastal_calibration.config.schema.PathConfig.geogrid_file","title":"geogrid_file","text":"<pre><code>geogrid_file(sim)\n</code></pre> <p>Geogrid file path for the given domain.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>def geogrid_file(self, sim: SimulationConfig) -&gt; Path:\n    \"\"\"Geogrid file path for the given domain.\"\"\"\n    return self.parm_nwm / sim.inland_domain / sim.geo_grid\n</code></pre>"},{"location":"reference/api/#modelconfig","title":"ModelConfig","text":""},{"location":"reference/api/#coastal_calibration.config.schema.ModelConfig","title":"ModelConfig","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for model-specific configuration.</p> <p>Each concrete subclass owns its compute parameters, environment variable construction, stage ordering, validation, and SLURM script generation. This keeps model-specific concerns out of the shared configuration and makes adding new models straightforward: create a new subclass, implement the abstract methods, and register it in :data:<code>MODEL_REGISTRY</code>.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.ModelConfig.model_name","title":"model_name  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>model_name\n</code></pre> <p>Return the model identifier string (e.g. <code>'schism'</code>, <code>'sfincs'</code>).</p>"},{"location":"reference/api/#coastal_calibration.config.schema.ModelConfig.stage_order","title":"stage_order  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>stage_order\n</code></pre> <p>Ordered list of stage names for this model's pipeline.</p>"},{"location":"reference/api/#coastal_calibration.config.schema.ModelConfig.build_environment","title":"build_environment  <code>abstractmethod</code>","text":"<pre><code>build_environment(env, config)\n</code></pre> <p>Add model-specific environment variables to env (mutating).</p> <p>Called by :meth:<code>WorkflowStage.build_environment</code> after shared variables have been populated.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>@abstractmethod\ndef build_environment(self, env: dict[str, str], config: CoastalCalibConfig) -&gt; dict[str, str]:\n    \"\"\"Add model-specific environment variables to *env* (mutating).\n\n    Called by :meth:`WorkflowStage.build_environment` after shared\n    variables have been populated.\n    \"\"\"\n</code></pre>"},{"location":"reference/api/#coastal_calibration.config.schema.ModelConfig.validate","title":"validate  <code>abstractmethod</code>","text":"<pre><code>validate(config)\n</code></pre> <p>Return model-specific validation errors.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>@abstractmethod\ndef validate(self, config: CoastalCalibConfig) -&gt; list[str]:\n    \"\"\"Return model-specific validation errors.\"\"\"\n</code></pre>"},{"location":"reference/api/#coastal_calibration.config.schema.ModelConfig.create_stages","title":"create_stages  <code>abstractmethod</code>","text":"<pre><code>create_stages(config, monitor)\n</code></pre> <p>Construct and return the <code>{name: stage}</code> dictionary.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>@abstractmethod\ndef create_stages(self, config: CoastalCalibConfig, monitor: Any) -&gt; dict[str, Any]:\n    \"\"\"Construct and return the ``{name: stage}`` dictionary.\"\"\"\n</code></pre>"},{"location":"reference/api/#coastal_calibration.config.schema.ModelConfig.generate_job_script_lines","title":"generate_job_script_lines  <code>abstractmethod</code>","text":"<pre><code>generate_job_script_lines(config)\n</code></pre> <p>Return <code>#SBATCH</code> directives specific to this model's compute needs.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>@abstractmethod\ndef generate_job_script_lines(self, config: CoastalCalibConfig) -&gt; list[str]:\n    \"\"\"Return ``#SBATCH`` directives specific to this model's compute needs.\"\"\"\n</code></pre>"},{"location":"reference/api/#coastal_calibration.config.schema.ModelConfig.to_dict","title":"to_dict  <code>abstractmethod</code>","text":"<pre><code>to_dict()\n</code></pre> <p>Serialize model-specific fields to a dictionary.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>@abstractmethod\ndef to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Serialize model-specific fields to a dictionary.\"\"\"\n</code></pre>"},{"location":"reference/api/#schismmodelconfig","title":"SchismModelConfig","text":""},{"location":"reference/api/#coastal_calibration.config.schema.SchismModelConfig","title":"SchismModelConfig  <code>dataclass</code>","text":"<pre><code>SchismModelConfig(\n    nodes=2,\n    ntasks_per_node=18,\n    exclusive=True,\n    nscribes=2,\n    omp_num_threads=2,\n    oversubscribe=False,\n    binary=_DEFAULT_SCHISM_BINARY,\n    include_noaa_gages=False,\n)\n</code></pre> <p>               Bases: <code>ModelConfig</code></p> <p>SCHISM model configuration.</p> <p>Contains compute parameters (MPI layout, SCHISM binary) that were previously split across <code>MPIConfig</code> and <code>SlurmConfig</code>.</p> PARAMETER DESCRIPTION <code>nodes</code> <p>Number of SLURM nodes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>ntasks_per_node</code> <p>MPI tasks per node.</p> <p> TYPE: <code>int</code> DEFAULT: <code>18</code> </p> <code>exclusive</code> <p>Request exclusive node access.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>nscribes</code> <p>Number of SCHISM scribe processes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>omp_num_threads</code> <p>OpenMP threads per MPI rank.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>oversubscribe</code> <p>Allow MPI oversubscription.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>binary</code> <p>SCHISM executable name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>_DEFAULT_SCHISM_BINARY</code> </p>"},{"location":"reference/api/#coastal_calibration.config.schema.SchismModelConfig.total_tasks","title":"total_tasks  <code>property</code>","text":"<pre><code>total_tasks\n</code></pre> <p>Total number of MPI tasks (nodes * ntasks_per_node).</p>"},{"location":"reference/api/#coastal_calibration.config.schema.SchismModelConfig.schism_mesh","title":"schism_mesh","text":"<pre><code>schism_mesh(sim, paths)\n</code></pre> <p>SCHISM ESMF mesh file path for the given domain.</p> Source code in <code>src/coastal_calibration/config/schema.py</code> <pre><code>def schism_mesh(self, sim: SimulationConfig, paths: PathConfig) -&gt; Path:\n    \"\"\"SCHISM ESMF mesh file path for the given domain.\"\"\"\n    return paths.parm_nwm / \"coastal\" / sim.coastal_domain / \"hgrid.nc\"\n</code></pre>"},{"location":"reference/api/#sfincsmodelconfig","title":"SfincsModelConfig","text":""},{"location":"reference/api/#coastal_calibration.config.schema.SfincsModelConfig","title":"SfincsModelConfig  <code>dataclass</code>","text":"<pre><code>SfincsModelConfig(\n    prebuilt_dir,\n    model_root=None,\n    include_noaa_gages=False,\n    observation_points=list(),\n    observation_locations_file=None,\n    merge_observations=False,\n    discharge_locations_file=None,\n    merge_discharge=False,\n    include_precip=False,\n    include_wind=False,\n    include_pressure=False,\n    container_tag=\"latest\",\n    container_image=None,\n    omp_num_threads=0,\n)\n</code></pre> <p>               Bases: <code>ModelConfig</code></p> <p>SFINCS model configuration.</p> <p>SFINCS runs on a single node using OpenMP (all available cores). There is no MPI or multi-node support.</p> PARAMETER DESCRIPTION <code>prebuilt_dir</code> <p>Path to the directory containing the pre-built model files (<code>sfincs.inp</code>, <code>sfincs.nc</code>, <code>region.geojson</code>, etc.).</p> <p> TYPE: <code>Path</code> </p> <code>model_root</code> <p>Output directory for the built model.  Defaults to <code>{work_dir}/sfincs_model</code>.</p> <p> TYPE: <code>Path</code> DEFAULT: <code>None</code> </p> <code>include_noaa_gages</code> <p>When True, automatically query NOAA CO-OPS for water level stations within the model domain and add them as observation points.  Requires the <code>plot</code> optional dependencies.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>observation_points</code> <p>Observation point specifications as list of dicts with <code>x</code>, <code>y</code>, <code>name</code> keys (coordinates in model CRS).</p> <p> TYPE: <code>list</code> DEFAULT: <code>list()</code> </p> <code>observation_locations_file</code> <p>Path to a GeoJSON file with observation point locations.</p> <p> TYPE: <code>Path</code> DEFAULT: <code>None</code> </p> <code>merge_observations</code> <p>Whether to merge with pre-existing observation points.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>discharge_locations_file</code> <p>Path to a SFINCS <code>.src</code> or GeoJSON with discharge source point locations.</p> <p> TYPE: <code>Path</code> DEFAULT: <code>None</code> </p> <code>merge_discharge</code> <p>Whether to merge with pre-existing discharge source points.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>include_precip</code> <p>When True, add precipitation forcing from the meteorological data catalog entry (derived from <code>simulation.meteo_source</code>).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>include_wind</code> <p>When True, add spatially-varying wind forcing (<code>wind10_u</code>, <code>wind10_v</code>) from the meteorological data catalog entry.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>include_pressure</code> <p>When True, add spatially-varying atmospheric pressure forcing (<code>press_msl</code>) and enable barometric correction (<code>baro=1</code>).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>container_tag</code> <p>Tag for the <code>deltares/sfincs-cpu</code> Docker/Singularity image.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'latest'</code> </p> <code>container_image</code> <p>Path to a pre-pulled Singularity SIF file.</p> <p> TYPE: <code>Path</code> DEFAULT: <code>None</code> </p> <code>omp_num_threads</code> <p>Number of OpenMP threads.  Defaults to the number of physical CPU cores on the current machine (see :func:<code>~coastal_calibration.utils.system.get_cpu_count</code>). On HPC nodes this auto-detects correctly; on a local laptop it avoids over-subscribing the system.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p>"},{"location":"reference/api/#monitoringconfig","title":"MonitoringConfig","text":""},{"location":"reference/api/#coastal_calibration.config.schema.MonitoringConfig","title":"MonitoringConfig  <code>dataclass</code>","text":"<pre><code>MonitoringConfig(\n    log_level=\"INFO\",\n    log_file=None,\n    enable_progress_tracking=True,\n    enable_timing=True,\n)\n</code></pre> <p>Workflow monitoring configuration.</p>"},{"location":"reference/api/#downloadconfig","title":"DownloadConfig","text":""},{"location":"reference/api/#coastal_calibration.config.schema.DownloadConfig","title":"DownloadConfig  <code>dataclass</code>","text":"<pre><code>DownloadConfig(\n    enabled=True,\n    skip_existing=True,\n    timeout=600,\n    raise_on_error=True,\n    limit_per_host=4,\n)\n</code></pre> <p>Data download configuration.</p>"},{"location":"reference/api/#workflow-runner","title":"Workflow Runner","text":""},{"location":"reference/api/#coastalcalibrunner","title":"CoastalCalibRunner","text":""},{"location":"reference/api/#coastal_calibration.runner.CoastalCalibRunner","title":"CoastalCalibRunner","text":"<pre><code>CoastalCalibRunner(config)\n</code></pre> <p>Main workflow runner for coastal model calibration.</p> <p>This class orchestrates the entire calibration workflow, managing stage execution, SLURM job submission, and progress monitoring.</p> <p>Supports both SCHISM (<code>model=\"schism\"</code>, default) and SFINCS (<code>model=\"sfincs\"</code>) pipelines.  The model type is selected via <code>config.model</code>.</p> <p>Initialize the workflow runner.</p> PARAMETER DESCRIPTION <code>config</code> <p>Coastal calibration configuration.</p> <p> TYPE: <code>CoastalCalibConfig</code> </p> Source code in <code>src/coastal_calibration/runner.py</code> <pre><code>def __init__(self, config: CoastalCalibConfig) -&gt; None:\n    \"\"\"Initialize the workflow runner.\n\n    Parameters\n    ----------\n    config : CoastalCalibConfig\n        Coastal calibration configuration.\n    \"\"\"\n    self.config = config\n\n    # Ensure log directory exists early so file logging can start.\n    config.paths.work_dir.mkdir(parents=True, exist_ok=True)\n\n    # Set up file logging *before* creating the monitor so that\n    # every message (including third-party) is captured on disk.\n    if not config.monitoring.log_file:\n        log_path = generate_log_path(config.paths.work_dir)\n        configure_logger(file=str(log_path), file_level=\"DEBUG\")\n\n    # Silence noisy third-party loggers (HydroMT, xarray, ...)\n    silence_third_party_loggers()\n\n    self.monitor = WorkflowMonitor(config.monitoring)\n    self._slurm: SlurmManager | None = None\n    self._stages: dict[str, WorkflowStage] = {}\n    self._results: dict[str, Any] = {}\n</code></pre>"},{"location":"reference/api/#coastal_calibration.runner.CoastalCalibRunner.validate","title":"validate","text":"<pre><code>validate()\n</code></pre> <p>Validate configuration and prerequisites.</p> RETURNS DESCRIPTION <code>list of str</code> <p>List of validation error messages (empty if valid).</p> Source code in <code>src/coastal_calibration/runner.py</code> <pre><code>def validate(self) -&gt; list[str]:\n    \"\"\"Validate configuration and prerequisites.\n\n    Returns\n    -------\n    list of str\n        List of validation error messages (empty if valid).\n    \"\"\"\n    errors = []\n\n    config_errors = self.config.validate()\n    errors.extend(config_errors)\n\n    self._init_stages()\n    for name, stage in self._stages.items():\n        stage_errors = stage.validate()\n        errors.extend(f\"[{name}] {error}\" for error in stage_errors)\n\n    return errors\n</code></pre>"},{"location":"reference/api/#coastal_calibration.runner.CoastalCalibRunner.submit","title":"submit","text":"<pre><code>submit(wait=False, log_file=None)\n</code></pre> <p>Submit workflow as a SLURM job.</p> <p>The download stage (if enabled) runs on the login node before submitting, so that expensive compute nodes are not wasted on sequential file downloads.</p> PARAMETER DESCRIPTION <code>wait</code> <p>If True, wait for job completion (interactive mode). If False, return immediately after job submission.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>log_file</code> <p>Custom path for SLURM output log. If not provided, logs are written to /slurm-.out. <p> TYPE: <code>Path</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>WorkflowResult</code> <p>Result with job submission details.</p> Source code in <code>src/coastal_calibration/runner.py</code> <pre><code>def submit(self, wait: bool = False, log_file: Path | None = None) -&gt; WorkflowResult:\n    \"\"\"Submit workflow as a SLURM job.\n\n    The download stage (if enabled) runs on the login node before\n    submitting, so that expensive compute nodes are not wasted on\n    sequential file downloads.\n\n    Parameters\n    ----------\n    wait : bool, default False\n        If True, wait for job completion (interactive mode).\n        If False, return immediately after job submission.\n    log_file : Path, optional\n        Custom path for SLURM output log. If not provided, logs are\n        written to &lt;work_dir&gt;/slurm-&lt;job_id&gt;.out.\n\n    Returns\n    -------\n    WorkflowResult\n        Result with job submission details.\n    \"\"\"\n    start_time = datetime.now()\n\n    validation_errors = self.validate()\n    if validation_errors:\n        return WorkflowResult(\n            success=False,\n            job_id=None,\n            start_time=start_time,\n            end_time=datetime.now(),\n            stages_completed=[],\n            stages_failed=[],\n            outputs={},\n            errors=validation_errors,\n        )\n\n    self._prepare_work_directory()\n\n    # Run download on the login node before submitting the SLURM job\n    if self.config.download.enabled:\n        self.monitor.info(\"Running download stage on login node...\")\n        self._init_stages()\n        download_stage = self._stages[\"download\"]\n        try:\n            download_stage.run()\n            self.monitor.info(\"Download stage completed\")\n        except Exception as e:\n            return WorkflowResult(\n                success=False,\n                job_id=None,\n                start_time=start_time,\n                end_time=datetime.now(),\n                stages_completed=[],\n                stages_failed=[\"download\"],\n                outputs={},\n                errors=[f\"Download stage failed: {e}\"],\n            )\n\n    job_script = self.config.paths.work_dir / \"submit_job.sh\"\n    self.slurm.generate_job_script(job_script, log_file=log_file)\n\n    self._generate_runner_script()\n\n    job_id = self.slurm.submit_job(job_script)\n\n    if not wait:\n        # Return immediately without waiting for job completion\n        return WorkflowResult(\n            success=True,\n            job_id=job_id,\n            start_time=start_time,\n            end_time=datetime.now(),\n            stages_completed=[],\n            stages_failed=[],\n            outputs={\"slurm_status\": \"SUBMITTED\"},\n            errors=[],\n        )\n\n    final_status = self.slurm.wait_for_job(job_id)\n\n    success = final_status.state == JobState.COMPLETED\n    errors = []\n    if not success:\n        errors.append(f\"Job ended with state: {final_status.state.value}\")\n        # Filter out empty reasons and SLURM's literal \"None\" string\n        if final_status.reason and final_status.reason.lower() != \"none\":\n            errors.append(f\"Reason: {final_status.reason}\")\n\n    return WorkflowResult(\n        success=success,\n        job_id=job_id,\n        start_time=start_time,\n        end_time=datetime.now(),\n        stages_completed=self.STAGE_ORDER if success else [],\n        stages_failed=[] if success else [\"unknown\"],\n        outputs={\"slurm_status\": final_status.state.value},\n        errors=errors,\n    )\n</code></pre>"},{"location":"reference/api/#coastal_calibration.runner.CoastalCalibRunner.run","title":"run","text":"<pre><code>run(start_from=None, stop_after=None, dry_run=False)\n</code></pre> <p>Execute the calibration workflow.</p> PARAMETER DESCRIPTION <code>start_from</code> <p>Stage name to start from (skip earlier stages).</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>stop_after</code> <p>Stage name to stop after (skip later stages).</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>dry_run</code> <p>If True, validate but don't execute.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>WorkflowResult</code> <p>Result with execution details.</p> Source code in <code>src/coastal_calibration/runner.py</code> <pre><code>def run(\n    self,\n    start_from: str | None = None,\n    stop_after: str | None = None,\n    dry_run: bool = False,\n) -&gt; WorkflowResult:\n    \"\"\"Execute the calibration workflow.\n\n    Parameters\n    ----------\n    start_from : str, optional\n        Stage name to start from (skip earlier stages).\n    stop_after : str, optional\n        Stage name to stop after (skip later stages).\n    dry_run : bool, default False\n        If True, validate but don't execute.\n\n    Returns\n    -------\n    WorkflowResult\n        Result with execution details.\n    \"\"\"\n    start_time = datetime.now()\n    stages_completed: list[str] = []\n    stages_failed: list[str] = []\n    outputs: dict[str, Any] = {}\n    errors: list[str] = []\n\n    validation_errors = self.validate()\n    if validation_errors:\n        return WorkflowResult(\n            success=False,\n            job_id=None,\n            start_time=start_time,\n            end_time=datetime.now(),\n            stages_completed=[],\n            stages_failed=[],\n            outputs={},\n            errors=validation_errors,\n        )\n\n    if dry_run:\n        self.monitor.info(\"Dry run mode - validation passed, no execution\")\n        return WorkflowResult(\n            success=True,\n            job_id=None,\n            start_time=start_time,\n            end_time=datetime.now(),\n            stages_completed=[],\n            stages_failed=[],\n            outputs={\"dry_run\": True},\n            errors=[],\n        )\n\n    self.monitor.register_stages(self.STAGE_ORDER)\n    self.monitor.start_workflow()\n\n    stages_to_run = self._get_stages_to_run(start_from, stop_after)\n\n    current_stage = \"\"\n    try:\n        for current_stage in stages_to_run:\n            stage = self._stages[current_stage]\n\n            with self.monitor.stage_context(current_stage, stage.description):\n                result = stage.run()\n                self._results[current_stage] = result\n                outputs[current_stage] = result\n                stages_completed.append(current_stage)\n\n        self.monitor.end_workflow(success=True)\n        success = True\n\n    except Exception as e:\n        self.monitor.error(f\"Workflow failed: {e}\")\n        self.monitor.end_workflow(success=False)\n        errors.append(str(e))\n        stages_failed.append(current_stage)\n        success = False\n\n    result = WorkflowResult(\n        success=success,\n        job_id=None,\n        start_time=start_time,\n        end_time=datetime.now(),\n        stages_completed=stages_completed,\n        stages_failed=stages_failed,\n        outputs=outputs,\n        errors=errors,\n    )\n\n    result_file = self.config.paths.work_dir / \"workflow_result.json\"\n    result.save(result_file)\n    self.monitor.save_progress(self.config.paths.work_dir / \"workflow_progress.json\")\n\n    return result\n</code></pre>"},{"location":"reference/api/#workflowresult","title":"WorkflowResult","text":""},{"location":"reference/api/#coastal_calibration.runner.WorkflowResult","title":"WorkflowResult  <code>dataclass</code>","text":"<pre><code>WorkflowResult(\n    success,\n    job_id,\n    start_time,\n    end_time,\n    stages_completed,\n    stages_failed,\n    outputs,\n    errors,\n)\n</code></pre> <p>Result of a workflow execution.</p>"},{"location":"reference/api/#coastal_calibration.runner.WorkflowResult.duration_seconds","title":"duration_seconds  <code>property</code>","text":"<pre><code>duration_seconds\n</code></pre> <p>Get workflow duration in seconds.</p>"},{"location":"reference/api/#coastal_calibration.runner.WorkflowResult.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Convert to dictionary.</p> Source code in <code>src/coastal_calibration/runner.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert to dictionary.\"\"\"\n    return {\n        \"success\": self.success,\n        \"job_id\": self.job_id,\n        \"start_time\": self.start_time.isoformat(),\n        \"end_time\": self.end_time.isoformat() if self.end_time else None,\n        \"duration_seconds\": self.duration_seconds,\n        \"stages_completed\": self.stages_completed,\n        \"stages_failed\": self.stages_failed,\n        \"outputs\": self.outputs,\n        \"errors\": self.errors,\n    }\n</code></pre>"},{"location":"reference/api/#coastal_calibration.runner.WorkflowResult.save","title":"save","text":"<pre><code>save(path)\n</code></pre> <p>Save result to JSON file.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to output JSON file. Parent directories will be created if they don't exist.</p> <p> TYPE: <code>Path or str</code> </p> Source code in <code>src/coastal_calibration/runner.py</code> <pre><code>def save(self, path: Path | str) -&gt; None:\n    \"\"\"Save result to JSON file.\n\n    Parameters\n    ----------\n    path : Path or str\n        Path to output JSON file. Parent directories will be created\n        if they don't exist.\n    \"\"\"\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    path.write_text(json.dumps(self.to_dict(), indent=2))\n</code></pre>"},{"location":"reference/api/#downloader","title":"Downloader","text":""},{"location":"reference/api/#validate_date_ranges","title":"validate_date_ranges","text":""},{"location":"reference/api/#coastal_calibration.downloader.validate_date_ranges","title":"validate_date_ranges","text":"<pre><code>validate_date_ranges(\n    start_time,\n    end_time,\n    meteo_source,\n    coastal_source,\n    domain,\n)\n</code></pre> <p>Validate that requested dates are within available ranges.</p> Source code in <code>src/coastal_calibration/downloader.py</code> <pre><code>def validate_date_ranges(\n    start_time: datetime,\n    end_time: datetime,\n    meteo_source: str,\n    coastal_source: str,\n    domain: str,\n) -&gt; list[str]:\n    \"\"\"Validate that requested dates are within available ranges.\"\"\"\n    errors: list[str] = []\n\n    meteo_range = get_date_range(meteo_source, domain)\n    if meteo_range:\n        error = meteo_range.validate(start_time, end_time)\n        if error:\n            errors.append(error)\n\n    if coastal_source != \"tpxo\":\n        coastal_range = get_date_range(coastal_source, domain)\n        if coastal_range:\n            error = coastal_range.validate(start_time, end_time)\n            if error:\n                errors.append(error)\n\n    return errors\n</code></pre>"},{"location":"reference/api/#type-aliases","title":"Type Aliases","text":"<pre><code># Model type\nModelType = Literal[\"schism\", \"sfincs\"]\n\n# Meteorological data source\nMeteoSource = Literal[\"nwm_retro\", \"nwm_ana\"]\n\n# Coastal domain identifier\nCoastalDomain = Literal[\"prvi\", \"hawaii\", \"atlgulf\", \"pacific\"]\n\n# Boundary condition source\nBoundarySource = Literal[\"tpxo\", \"stofs\"]\n\n# Logging level\nLogLevel = Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n</code></pre>"},{"location":"reference/api/#constants","title":"Constants","text":""},{"location":"reference/api/#default-paths","title":"Default Paths","text":"<pre><code>DEFAULT_SING_IMAGE_PATH = Path(\"/ngencerf-app/singularity/ngen-coastal.sif\")\nDEFAULT_PARM_DIR = Path(\"/ngen-test/coastal/ngwpc-coastal\")\nDEFAULT_NGEN_APP_DIR = Path(\"/ngen-app\")\nDEFAULT_NFS_MOUNT = Path(\"/ngen-test\")\nDEFAULT_CONDA_ENV_NAME = \"ngen_forcing_coastal\"\nDEFAULT_NWM_VERSION = \"v3.0.6\"\nDEFAULT_OTPS_DIR = Path(\"/ngen-app/OTPSnc\")\nDEFAULT_SLURM_PARTITION = \"c5n-18xlarge\"\n</code></pre>"},{"location":"reference/api/#default-path-templates","title":"Default Path Templates","text":"<pre><code>DEFAULT_WORK_DIR_TEMPLATE = (\n    \"/ngen-test/coastal/${slurm.user}/\"\n    \"${model}_${simulation.coastal_domain}_${boundary.source}_${simulation.meteo_source}/\"\n    \"${model}_${simulation.start_date}\"\n)\n\nDEFAULT_RAW_DOWNLOAD_DIR_TEMPLATE = (\n    \"/ngen-test/coastal/${slurm.user}/\"\n    \"${model}_${simulation.coastal_domain}_${boundary.source}_${simulation.meteo_source}/\"\n    \"raw_data\"\n)\n</code></pre>"},{"location":"reference/api/#model-registry","title":"Model Registry","text":"<pre><code>MODEL_REGISTRY: dict[str, type[ModelConfig]] = {\n    \"schism\": SchismModelConfig,\n    \"sfincs\": SfincsModelConfig,\n}\n</code></pre>"},{"location":"user-guide/cli/","title":"CLI Reference","text":"<p>The <code>coastal-calibration</code> command-line interface provides commands for managing SCHISM and SFINCS coastal model workflows.</p>"},{"location":"user-guide/cli/#global-options","title":"Global Options","text":"<pre><code>coastal-calibration --help\ncoastal-calibration --version\n</code></pre>"},{"location":"user-guide/cli/#commands","title":"Commands","text":""},{"location":"user-guide/cli/#init","title":"init","text":"<p>Create a minimal configuration file.</p> <pre><code>coastal-calibration init OUTPUT [OPTIONS]\n</code></pre> <p>Arguments:</p> Argument Description <code>OUTPUT</code> Path where the configuration will be written <p>Options:</p> Option Description Default <code>--domain</code> Coastal domain to use <code>pacific</code> <code>--force</code>, <code>-f</code> Overwrite existing file without prompt False <code>--model</code> Model type (<code>schism</code> or <code>sfincs</code>) <code>schism</code> <p>Examples:</p> <pre><code># Generate default SCHISM configuration\ncoastal-calibration init config.yaml\n\n# Generate configuration for a specific domain\ncoastal-calibration init pacific_config.yaml --domain pacific\n\n# Generate SFINCS configuration\ncoastal-calibration init sfincs_config.yaml --domain atlgulf --model sfincs\n\n# Overwrite existing file\ncoastal-calibration init config.yaml --force\n</code></pre>"},{"location":"user-guide/cli/#validate","title":"validate","text":"<p>Validate a configuration file for errors and warnings.</p> <pre><code>coastal-calibration validate &lt;config&gt;\n</code></pre> <p>Arguments:</p> Argument Description <code>config</code> Path to the configuration file <p>Examples:</p> <pre><code>coastal-calibration validate config.yaml\n</code></pre> <p>Output:</p> <pre><code>\u2713 Configuration is valid\n</code></pre> <p>Or with errors:</p> <pre><code>\u2717 Configuration has errors:\n  - slurm.user is required\n  - Simulation dates outside nwm_ana range (2018-09-17 to present)\n</code></pre>"},{"location":"user-guide/cli/#submit","title":"submit","text":"<p>Submit a workflow as a SLURM job.</p> <pre><code>coastal-calibration submit &lt;config&gt; [OPTIONS]\n</code></pre> <p>Arguments:</p> Argument Description <code>config</code> Path to the configuration file <p>Options:</p> Option Description Default <code>--interactive</code>, <code>-i</code> Wait for job completion with updates False <p>Examples:</p> <pre><code># Submit and return immediately\ncoastal-calibration submit config.yaml\n\n# Submit and wait for completion\ncoastal-calibration submit config.yaml --interactive\ncoastal-calibration submit config.yaml -i\n</code></pre>"},{"location":"user-guide/cli/#run","title":"run","text":"<p>Run the workflow directly (for testing or inside a SLURM job).</p> <pre><code>coastal-calibration run &lt;config&gt; [OPTIONS]\n</code></pre> <p>Arguments:</p> Argument Description <code>config</code> Path to the configuration file <p>Options:</p> Option Description Default <code>--start-from</code> Stage to start from First <code>--stop-after</code> Stage to stop after Last <code>--dry-run</code> Validate configuration without executing False <p>Available Stages (SCHISM):</p> <ul> <li><code>download</code></li> <li><code>pre_forcing</code></li> <li><code>nwm_forcing</code></li> <li><code>post_forcing</code></li> <li><code>update_params</code></li> <li><code>boundary_conditions</code></li> <li><code>pre_schism</code></li> <li><code>schism_run</code></li> <li><code>post_schism</code></li> </ul> <p>Available Stages (SFINCS):</p> <ul> <li><code>download</code></li> <li><code>sfincs_symlinks</code></li> <li><code>sfincs_data_catalog</code></li> <li><code>sfincs_init</code></li> <li><code>sfincs_timing</code></li> <li><code>sfincs_forcing</code></li> <li><code>sfincs_obs</code></li> <li><code>sfincs_discharge</code></li> <li><code>sfincs_precip</code></li> <li><code>sfincs_write</code></li> <li><code>sfincs_run</code></li> </ul> <p>Examples:</p> <pre><code># Run entire workflow\ncoastal-calibration run config.yaml\n\n# Run only forcing stages (SCHISM)\ncoastal-calibration run config.yaml --start-from pre_forcing --stop-after post_forcing\n\n# Run only the model build (SFINCS)\ncoastal-calibration run config.yaml --stop-after sfincs_write\n\n# Run only the model execution (SFINCS)\ncoastal-calibration run config.yaml --start-from sfincs_run\n</code></pre>"},{"location":"user-guide/cli/#stages","title":"stages","text":"<p>List all available workflow stages.</p> <pre><code>coastal-calibration stages [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--model</code> Show stages for a specific model Show all <p>Examples:</p> <pre><code># List all stages for both models\ncoastal-calibration stages\n\n# List only SCHISM stages\ncoastal-calibration stages --model schism\n\n# List only SFINCS stages\ncoastal-calibration stages --model sfincs\n</code></pre> <p>Output (all):</p> <pre><code>SCHISM workflow stages:\n  1. download: Download NWM/STOFS data\n  2. pre_forcing: Prepare NWM forcing data\n  3. nwm_forcing: Generate atmospheric forcing (MPI)\n  4. post_forcing: Post-process forcing data\n  5. update_params: Create SCHISM param.nml\n  6. boundary_conditions: Generate boundary conditions\n  7. pre_schism: Prepare SCHISM inputs\n  8. schism_run: Run SCHISM model (MPI)\n  9. post_schism: Post-process SCHISM outputs\n\nSFINCS workflow stages:\n  1. download: Download NWM/STOFS data (optional)\n  2. sfincs_symlinks: Create .nc symlinks for NWM data\n  3. sfincs_data_catalog: Generate HydroMT data catalog\n  4. sfincs_init: Initialise SFINCS model (pre-built)\n  5. sfincs_timing: Set SFINCS timing\n  6. sfincs_forcing: Add water level forcing\n  7. sfincs_obs: Add observation points\n  8. sfincs_discharge: Add discharge sources\n  9. sfincs_precip: Add precipitation forcing\n  10. sfincs_write: Write SFINCS model\n  11. sfincs_run: Run SFINCS model (Singularity)\n</code></pre>"},{"location":"user-guide/cli/#exit-codes","title":"Exit Codes","text":"Code Description 0 Success 1 Configuration validation error 2 Runtime error 3 Job submission failed 4 Job execution failed"},{"location":"user-guide/cli/#environment-variables","title":"Environment Variables","text":"<p>The CLI respects these environment variables:</p> Variable Description <code>COASTAL_LOG_LEVEL</code> Override default log level <code>SLURM_JOB_ID</code> Detected when running in SLURM"},{"location":"user-guide/cli/#shell-completion","title":"Shell Completion","text":"<p>To enable shell completion (bash/zsh):</p> <pre><code># Bash\neval \"$(_COASTAL_CALIBRATION_COMPLETE=bash_source coastal-calibration)\"\n\n# Zsh\neval \"$(_COASTAL_CALIBRATION_COMPLETE=zsh_source coastal-calibration)\"\n</code></pre> <p>Add this to your shell profile for persistent completion.</p>"},{"location":"user-guide/configuration/","title":"Configuration","text":"<p>NWM Coastal uses YAML configuration files to define simulation parameters. This page documents all available configuration options.</p>"},{"location":"user-guide/configuration/#minimal-configuration","title":"Minimal Configuration","text":""},{"location":"user-guide/configuration/#schism-default","title":"SCHISM (default)","text":"<p>The simplest valid SCHISM configuration only requires:</p> <pre><code>slurm:\n  job_name: my_run\n  user: your_username\n\nsimulation:\n  start_date: 2021-06-11\n  duration_hours: 24\n  coastal_domain: hawaii\n  meteo_source: nwm_ana\n\nboundary:\n  source: stofs\n</code></pre> <p>All other parameters have sensible defaults. When no <code>model</code> key is present, SCHISM is assumed.</p>"},{"location":"user-guide/configuration/#sfincs","title":"SFINCS","text":"<p>A minimal SFINCS configuration requires a <code>model</code> key and a <code>model_config</code> section:</p> <pre><code>model: sfincs\n\nslurm:\n  job_name: my_sfincs_run\n  user: your_username\n\nsimulation:\n  start_date: 2025-06-01\n  duration_hours: 168\n  coastal_domain: atlgulf\n  meteo_source: nwm_ana\n\nboundary:\n  source: stofs\n\nmodel_config:\n  prebuilt_dir: /path/to/prebuilt/sfincs/model\n</code></pre>"},{"location":"user-guide/configuration/#variable-interpolation","title":"Variable Interpolation","text":"<p>Configuration values support variable interpolation using <code>${section.key}</code> syntax:</p> <pre><code>slurm:\n  user: john\n\nsimulation:\n  coastal_domain: hawaii\n\npaths:\n  work_dir: /data/${slurm.user}/${simulation.coastal_domain}\n  # Resolves to: /data/john/hawaii\n</code></pre>"},{"location":"user-guide/configuration/#default-path-templates","title":"Default Path Templates","text":"<p>If not specified, paths are automatically generated using model-aware templates:</p> Path Default Template <code>work_dir</code> <code>/ngen-test/coastal/${slurm.user}/${model}_${simulation.coastal_domain}_${boundary.source}_${simulation.meteo_source}/${model}_${simulation.start_date}</code> <code>raw_download_dir</code> <code>/ngen-test/coastal/${slurm.user}/${model}_${simulation.coastal_domain}_${boundary.source}_${simulation.meteo_source}/raw_data</code> <p>The <code>${model}</code> variable resolves to <code>schism</code> or <code>sfincs</code> based on the <code>model</code> key.</p>"},{"location":"user-guide/configuration/#configuration-sections","title":"Configuration Sections","text":""},{"location":"user-guide/configuration/#model-selection","title":"Model Selection","text":"<p>The top-level <code>model</code> key selects the model type. It defaults to <code>schism</code> if omitted.</p> <pre><code>model: sfincs  # or \"schism\" (default)\n</code></pre>"},{"location":"user-guide/configuration/#slurm-settings","title":"SLURM Settings","text":"<p>Configure SLURM job scheduling. Compute resources (nodes, tasks) are model-specific and live in the <code>model_config</code> section.</p> <pre><code>slurm:\n  job_name: coastal_calibration  # Job name shown in squeue\n  user: your_username            # Required: your SLURM username\n  partition: c5n-18xlarge        # SLURM partition\n  time_limit:                    # Time limit (HH:MM:SS), null for no limit\n  account:                       # SLURM account for billing\n  qos:                           # Quality of Service\n</code></pre> Parameter Type Default Description <code>job_name</code> string <code>coastal_calibration</code> SLURM job name <code>user</code> string required Your SLURM username <code>partition</code> string <code>c5n-18xlarge</code> SLURM partition <code>time_limit</code> string null Time limit <code>account</code> string null SLURM account <code>qos</code> string null Quality of Service"},{"location":"user-guide/configuration/#simulation-settings","title":"Simulation Settings","text":"<p>Define the simulation time period and domain:</p> <pre><code>simulation:\n  start_date: 2021-06-11         # Start date (ISO format)\n  duration_hours: 24             # Simulation length\n  coastal_domain: hawaii         # Domain name\n  meteo_source: nwm_ana          # Meteorological data source\n  timestep_seconds: 3600         # Forcing time step\n</code></pre> Parameter Type Default Options <code>start_date</code> datetime required ISO format date/datetime <code>duration_hours</code> int required Positive integer <code>coastal_domain</code> string required <code>hawaii</code>, <code>prvi</code>, <code>atlgulf</code>, <code>pacific</code> <code>meteo_source</code> string required <code>nwm_ana</code>, <code>nwm_retro</code> <code>timestep_seconds</code> int 3600 Forcing time step in seconds"},{"location":"user-guide/configuration/#supported-date-formats","title":"Supported Date Formats","text":"<p>The <code>start_date</code> field accepts multiple formats:</p> <pre><code>start_date: 2021-06-11              # Date only (midnight)\nstart_date: 2021-06-11T00:00:00     # ISO format with time\nstart_date: \"2021-06-11 00:00:00\"   # Date with space separator\nstart_date: 20210611                # Compact format\n</code></pre>"},{"location":"user-guide/configuration/#boundary-settings","title":"Boundary Settings","text":"<p>Configure boundary conditions:</p> <pre><code>boundary:\n  source: stofs          # Boundary condition source\n  stofs_file:            # Optional: explicit STOFS file path\n</code></pre> Parameter Type Default Options Description <code>source</code> string <code>tpxo</code> <code>tpxo</code>, <code>stofs</code> Boundary condition source <code>stofs_file</code> path null - Override STOFS file path"},{"location":"user-guide/configuration/#path-settings","title":"Path Settings","text":"<p>Configure file system paths:</p> <pre><code>paths:\n  work_dir: /path/to/work         # Working directory (auto-generated if not set)\n  raw_download_dir: /path/to/data # Download directory (auto-generated if not set)\n  nfs_mount: /ngen-test           # NFS mount point\n  singularity_image: /ngencerf-app/singularity/ngen-coastal.sif\n  ngen_app_dir: /ngen-app\n  hot_start_file:                 # Hot restart file for warm start\n  conda_env_name: ngen_forcing_coastal\n  parm_dir: /ngen-test/coastal/ngwpc-coastal\n</code></pre> Parameter Type Default <code>work_dir</code> path Auto-generated from template <code>raw_download_dir</code> path Auto-generated from template <code>nfs_mount</code> path <code>/ngen-test</code> <code>singularity_image</code> path <code>/ngencerf-app/singularity/ngen-coastal.sif</code> <code>ngen_app_dir</code> path <code>/ngen-app</code> <code>hot_start_file</code> path null <code>conda_env_name</code> string <code>ngen_forcing_coastal</code> <code>parm_dir</code> path <code>/ngen-test/coastal/ngwpc-coastal</code>"},{"location":"user-guide/configuration/#model-configuration","title":"Model Configuration","text":"<p>Model-specific parameters live in the <code>model_config</code> section. The contents depend on the <code>model</code> key.</p>"},{"location":"user-guide/configuration/#schism-model-configuration","title":"SCHISM Model Configuration","text":"<pre><code># model: schism (default, can be omitted)\nmodel_config:\n  nodes: 2                        # Number of compute nodes\n  ntasks_per_node: 18             # MPI tasks per node\n  exclusive: true                 # Request exclusive node access\n  nscribes: 2                     # SCHISM I/O scribes\n  omp_num_threads: 2              # OpenMP threads\n  oversubscribe: false            # Allow MPI oversubscription\n  binary: pschism_wcoss2_NO_PARMETIS_TVD-VL.openmpi\n</code></pre> Parameter Type Default <code>nodes</code> int 2 <code>ntasks_per_node</code> int 18 <code>exclusive</code> bool true <code>nscribes</code> int 2 <code>omp_num_threads</code> int 2 <code>oversubscribe</code> bool false <code>binary</code> string <code>pschism_wcoss2_NO_PARMETIS_TVD-VL.openmpi</code>"},{"location":"user-guide/configuration/#sfincs-model-configuration","title":"SFINCS Model Configuration","text":"<pre><code>model: sfincs\n\nmodel_config:\n  prebuilt_dir: /path/to/model    # Required: pre-built SFINCS model directory\n  observation_points: []          # Observation point coordinates\n  observation_locations_file:     # Observation locations file\n  merge_observations: false       # Merge observations into model\n  discharge_locations_file:       # Discharge source locations file\n  merge_discharge: false          # Merge discharge into model\n  omp_num_threads: 36             # OpenMP threads\n  container_tag: latest           # SFINCS container tag\n  container_image:                # Singularity image path\n</code></pre> Parameter Type Default <code>prebuilt_dir</code> path required <code>observation_points</code> list <code>[]</code> <code>observation_locations_file</code> path null <code>merge_observations</code> bool false <code>discharge_locations_file</code> path null <code>merge_discharge</code> bool false <code>omp_num_threads</code> int 36 <code>container_tag</code> string latest <code>container_image</code> path null"},{"location":"user-guide/configuration/#monitoring-settings","title":"Monitoring Settings","text":"<p>Configure logging and monitoring:</p> <pre><code>monitoring:\n  log_level: INFO                 # Logging verbosity\n  log_file:                       # Optional log file path\n  enable_progress_tracking: true  # Show progress bars\n  enable_timing: true             # Track stage timing\n</code></pre> Parameter Type Default Options <code>log_level</code> string <code>INFO</code> <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code> <code>log_file</code> path null Path to log file <code>enable_progress_tracking</code> bool true Show progress bars <code>enable_timing</code> bool true Track and report stage timing"},{"location":"user-guide/configuration/#download-settings","title":"Download Settings","text":"<p>Configure data download behavior:</p> <pre><code>download:\n  enabled: true           # Enable automatic downloads\n  skip_existing: true     # Skip already downloaded files\n  timeout: 600            # Download timeout in seconds\n  raise_on_error: true    # Fail on download errors\n  limit_per_host: 4       # Concurrent downloads per host\n</code></pre> Parameter Type Default Description <code>enabled</code> bool true Enable automatic downloads <code>skip_existing</code> bool true Skip already downloaded files <code>timeout</code> int 600 Download timeout (seconds) <code>raise_on_error</code> bool true Fail workflow on download errors <code>limit_per_host</code> int 4 Concurrent downloads per host"},{"location":"user-guide/configuration/#configuration-inheritance","title":"Configuration Inheritance","text":"<p>Use <code>_base</code> to inherit settings from another configuration file:</p> <pre><code># base.yaml - shared settings\nslurm:\n  job_name: coastal_sim\n  user: your_username\n\nsimulation:\n  duration_hours: 24\n  meteo_source: nwm_ana\n\nboundary:\n  source: stofs\n</code></pre> <pre><code># hawaii_run.yaml - inherits from base.yaml\n_base: base.yaml\n\nsimulation:\n  start_date: 2021-06-11\n  coastal_domain: hawaii\n</code></pre> <pre><code># prvi_run.yaml - different domain, same settings\n_base: base.yaml\n\nsimulation:\n  start_date: 2022-09-18\n  coastal_domain: prvi\n</code></pre> <p>This allows you to:</p> <ul> <li>Share common settings across multiple runs</li> <li>Override only the parameters that differ</li> <li>Maintain consistency across related simulations</li> </ul>"},{"location":"user-guide/configuration/#validation","title":"Validation","text":"<p>Validate your configuration before running:</p> <pre><code>coastal-calibration validate config.yaml\n</code></pre> <p>The validation checks:</p> <ul> <li>All required fields are present</li> <li>Date ranges are valid for selected data sources</li> <li>File paths exist (for required files)</li> <li>SLURM parameters are valid</li> <li>Model-specific configuration is consistent (e.g., nscribes &lt; total MPI tasks for     SCHISM)</li> </ul>"},{"location":"user-guide/python-api/","title":"Python API","text":"<p>The Python API provides programmatic access to the coastal calibration workflow, enabling integration with other tools and custom automation.</p>"},{"location":"user-guide/python-api/#basic-usage","title":"Basic Usage","text":"<pre><code>from coastal_calibration import CoastalCalibConfig, CoastalCalibRunner\n\n# Load configuration from YAML\nconfig = CoastalCalibConfig.from_yaml(\"config.yaml\")\n\n# Create a runner\nrunner = CoastalCalibRunner(config)\n\n# Validate configuration\nerrors = runner.validate()\nif errors:\n    for error in errors:\n        print(f\"Error: {error}\")\nelse:\n    # Submit the job\n    result = runner.submit(wait=True)\n\n    if result.success:\n        print(f\"Job {result.job_id} completed successfully\")\n    else:\n        print(f\"Job failed: {result.errors}\")\n</code></pre>"},{"location":"user-guide/python-api/#configuration","title":"Configuration","text":""},{"location":"user-guide/python-api/#loading-configuration","title":"Loading Configuration","text":"<pre><code>from coastal_calibration import CoastalCalibConfig\n\n# From YAML file\nconfig = CoastalCalibConfig.from_yaml(\"config.yaml\")\n\n# Access configuration values\nprint(config.slurm.job_name)\nprint(config.simulation.coastal_domain)\nprint(config.paths.work_dir)\nprint(config.model)  # \"schism\" or \"sfincs\"\n</code></pre>"},{"location":"user-guide/python-api/#creating-schism-configuration-programmatically","title":"Creating SCHISM Configuration Programmatically","text":"<pre><code>from datetime import datetime\nfrom pathlib import Path\nfrom coastal_calibration import (\n    CoastalCalibConfig,\n    SlurmConfig,\n    SimulationConfig,\n    BoundaryConfig,\n    PathConfig,\n    SchismModelConfig,\n    MonitoringConfig,\n    DownloadConfig,\n)\n\nconfig = CoastalCalibConfig(\n    slurm=SlurmConfig(\n        job_name=\"my_simulation\",\n        user=\"your_username\",\n    ),\n    simulation=SimulationConfig(\n        start_date=datetime(2021, 6, 11),\n        duration_hours=24,\n        coastal_domain=\"hawaii\",\n        meteo_source=\"nwm_ana\",\n    ),\n    boundary=BoundaryConfig(source=\"stofs\"),\n    paths=PathConfig(\n        work_dir=Path(\"/ngen-test/coastal/your_username/my_run\"),\n        raw_download_dir=Path(\"/ngen-test/coastal/your_username/downloads\"),\n    ),\n    model_config=SchismModelConfig(\n        nodes=2,\n        ntasks_per_node=18,\n    ),\n)\n\n# Save to YAML\nconfig.to_yaml(\"generated_config.yaml\")\n</code></pre>"},{"location":"user-guide/python-api/#creating-sfincs-configuration-programmatically","title":"Creating SFINCS Configuration Programmatically","text":"<pre><code>from datetime import datetime\nfrom pathlib import Path\nfrom coastal_calibration import (\n    CoastalCalibConfig,\n    SlurmConfig,\n    SimulationConfig,\n    BoundaryConfig,\n    PathConfig,\n    SfincsModelConfig,\n)\n\nTEXAS_DIR = Path(\"/path/to/texas/model\")\n\nconfig = CoastalCalibConfig(\n    slurm=SlurmConfig(user=\"your_username\"),\n    simulation=SimulationConfig(\n        start_date=datetime(2025, 6, 1),\n        duration_hours=168,\n        coastal_domain=\"atlgulf\",\n        meteo_source=\"nwm_ana\",\n    ),\n    boundary=BoundaryConfig(source=\"stofs\"),\n    paths=PathConfig(\n        work_dir=Path(\"/tmp/sfincs_run\"),\n        raw_download_dir=Path(\"/tmp/sfincs_downloads\"),\n    ),\n    model_config=SfincsModelConfig(\n        prebuilt_dir=TEXAS_DIR,\n        discharge_locations_file=TEXAS_DIR / \"sfincs_nwm.src\",\n        observation_points=[\n            {\"x\": 830344.95, \"y\": 3187383.41, \"name\": \"Sargent\"},\n        ],\n        merge_observations=False,\n        merge_discharge=False,\n    ),\n)\n</code></pre>"},{"location":"user-guide/python-api/#configuration-validation","title":"Configuration Validation","text":"<pre><code>config = CoastalCalibConfig.from_yaml(\"config.yaml\")\n\n# Validate and get list of errors\nerrors = config.validate()\n\nif errors:\n    print(\"Configuration errors:\")\n    for error in errors:\n        print(f\"  - {error}\")\nelse:\n    print(\"Configuration is valid\")\n</code></pre>"},{"location":"user-guide/python-api/#workflow-execution","title":"Workflow Execution","text":""},{"location":"user-guide/python-api/#submit-to-slurm","title":"Submit to SLURM","text":"<pre><code>from coastal_calibration import CoastalCalibConfig, CoastalCalibRunner\n\nconfig = CoastalCalibConfig.from_yaml(\"config.yaml\")\nrunner = CoastalCalibRunner(config)\n\n# Submit and return immediately\nresult = runner.submit(wait=False)\nprint(f\"Job {result.job_id} submitted\")\n\n# Submit and wait for completion\nresult = runner.submit(wait=True)\nif result.success:\n    print(f\"Job completed in {result.duration_seconds:.1f}s\")\n</code></pre>"},{"location":"user-guide/python-api/#run-directly","title":"Run Directly","text":"<p>For testing or when already inside a SLURM job:</p> <pre><code># Run complete workflow\nresult = runner.run()\n\n# Run partial workflow\nresult = runner.run(start_from=\"pre_forcing\", stop_after=\"post_forcing\")\n\n# Run from a specific stage to the end\nresult = runner.run(start_from=\"pre_schism\")\n</code></pre>"},{"location":"user-guide/python-api/#workflow-result","title":"Workflow Result","text":"<p>The <code>WorkflowResult</code> object contains information about the execution:</p> <pre><code>result = runner.submit(wait=True)\n\nprint(f\"Success: {result.success}\")\nprint(f\"Job ID: {result.job_id}\")\nprint(f\"Duration: {result.duration_seconds}s\")\n\nif not result.success:\n    for error in result.errors:\n        print(f\"Error: {error}\")\n\n# Stage timing (if enable_timing is True)\nfor stage, duration in result.stage_durations.items():\n    print(f\"  {stage}: {duration:.1f}s\")\n</code></pre>"},{"location":"user-guide/python-api/#data-sources","title":"Data Sources","text":""},{"location":"user-guide/python-api/#check-available-date-ranges","title":"Check Available Date Ranges","text":"<pre><code>from coastal_calibration.downloader import validate_date_ranges\n\n# Validate dates for your configuration\nerrors = validate_date_ranges(\n    start_time=datetime(2021, 6, 11),\n    end_time=datetime(2021, 6, 12),\n    meteo_source=\"nwm_ana\",\n    boundary_source=\"stofs\",\n    coastal_domain=\"hawaii\",\n)\n\nif errors:\n    print(\"Date range errors:\", errors)\n</code></pre>"},{"location":"user-guide/python-api/#supported-data-sources","title":"Supported Data Sources","text":"Source Date Range Description <code>nwm_retro</code> 1979-02-01 to 2023-01-31 NWM Retrospective 3.0 <code>nwm_ana</code> 2018-09-17 to present NWM Analysis <code>stofs</code> 2020-12-30 to present STOFS water levels <code>glofs</code> 2005-09-30 to present Great Lakes OFS"},{"location":"user-guide/python-api/#logging","title":"Logging","text":"<p>Configure logging for the workflow:</p> <pre><code>import logging\nfrom coastal_calibration.utils.logging import setup_logger\n\n# Set up logging\nlogger = setup_logger(log_level=\"DEBUG\", log_file=\"workflow.log\")\n\n# Now run your workflow\nconfig = CoastalCalibConfig.from_yaml(\"config.yaml\")\nrunner = CoastalCalibRunner(config)\nresult = runner.submit(wait=True)\n</code></pre>"},{"location":"user-guide/python-api/#example-batch-processing","title":"Example: Batch Processing","text":"<p>Run multiple simulations with different parameters:</p> <pre><code>from datetime import datetime, timedelta\nfrom coastal_calibration import CoastalCalibConfig, CoastalCalibRunner\n\n# Load base configuration\nbase_config = CoastalCalibConfig.from_yaml(\"base_config.yaml\")\n\n# Run simulations for multiple dates\nstart_dates = [\n    datetime(2021, 6, 1),\n    datetime(2021, 6, 15),\n    datetime(2021, 7, 1),\n]\n\nresults = []\nfor start_date in start_dates:\n    # Modify configuration for this run\n    config = CoastalCalibConfig.from_yaml(\"base_config.yaml\")\n    config.simulation.start_date = start_date\n\n    # Update work directory for this run\n    date_str = start_date.strftime(\"%Y%m%d\")\n    config.paths.work_dir = config.paths.work_dir.parent / f\"run_{date_str}\"\n\n    # Submit\n    runner = CoastalCalibRunner(config)\n    result = runner.submit(wait=False)  # Don't wait, submit all jobs\n    results.append((start_date, result))\n\n# Report job IDs\nfor start_date, result in results:\n    print(f\"{start_date}: Job {result.job_id}\")\n</code></pre>"},{"location":"user-guide/python-api/#example-domain-comparison","title":"Example: Domain Comparison","text":"<p>Run the same simulation across multiple domains:</p> <pre><code>domains = [\"hawaii\", \"prvi\", \"atlgulf\", \"pacific\"]\n\nfor domain in domains:\n    config = CoastalCalibConfig.from_yaml(\"base_config.yaml\")\n    config.simulation.coastal_domain = domain\n\n    runner = CoastalCalibRunner(config)\n    errors = runner.validate()\n\n    if errors:\n        print(f\"{domain}: Validation failed - {errors}\")\n        continue\n\n    result = runner.submit(wait=True)\n    print(f\"{domain}: {'Success' if result.success else 'Failed'}\")\n</code></pre>"},{"location":"user-guide/workflow-stages/","title":"Workflow Stages","text":"<p>The coastal calibration workflow consists of sequential stages, each performing a specific task in the simulation pipeline. The stage order depends on the selected model (SCHISM or SFINCS).</p>"},{"location":"user-guide/workflow-stages/#schism-stage-overview","title":"SCHISM Stage Overview","text":"<pre><code>flowchart TD\n    A[download] --&gt; B[pre_forcing]\n    B --&gt; C[nwm_forcing]\n    C --&gt; D[post_forcing]\n    D --&gt; E[update_params]\n    E --&gt; F[boundary_conditions]\n    F --&gt; G[pre_schism]\n    G --&gt; H[schism_run]\n    H --&gt; I[post_schism]</code></pre>"},{"location":"user-guide/workflow-stages/#sfincs-stage-overview","title":"SFINCS Stage Overview","text":"<pre><code>flowchart TD\n    A[download] --&gt; B[sfincs_symlinks]\n    B --&gt; C[sfincs_data_catalog]\n    C --&gt; D[sfincs_init]\n    D --&gt; E[sfincs_timing]\n    E --&gt; F[sfincs_forcing]\n    F --&gt; G[sfincs_obs]\n    G --&gt; H[sfincs_discharge]\n    H --&gt; I[sfincs_precip]\n    I --&gt; J[sfincs_write]\n    J --&gt; K[sfincs_run]</code></pre>"},{"location":"user-guide/workflow-stages/#schism-stage-details","title":"SCHISM Stage Details","text":""},{"location":"user-guide/workflow-stages/#1-download","title":"1. download","text":"<p>Purpose: Download required input data from remote sources.</p> <p>Data Sources:</p> <ul> <li>NWM meteorological forcing (LDASIN files)</li> <li>NWM streamflow data (CHRTOUT files)</li> <li>STOFS or GLOFS water level data (when applicable)</li> </ul> <p>Runs On: Login node (before SLURM job submission)</p> <p>Outputs:</p> <pre><code>raw_download_dir/\n\u251c\u2500\u2500 meteo/nwm_ana/\n\u2502   \u2514\u2500\u2500 *.LDASIN_DOMAIN1.nc\n\u251c\u2500\u2500 hydro/nwm/\n\u2502   \u2514\u2500\u2500 *.CHRTOUT_DOMAIN1.nc\n\u2514\u2500\u2500 coastal/stofs/\n    \u2514\u2500\u2500 *.fields.cwl.nc\n</code></pre>"},{"location":"user-guide/workflow-stages/#2-pre_forcing","title":"2. pre_forcing","text":"<p>Purpose: Prepare NWM forcing data for SCHISM.</p> <p>Tasks:</p> <ul> <li>Copy and organize downloaded NWM files</li> <li>Set up directory structure for forcing generation</li> <li>Validate input data integrity</li> </ul> <p>Runs On: Compute node (inside Singularity)</p>"},{"location":"user-guide/workflow-stages/#3-nwm_forcing","title":"3. nwm_forcing","text":"<p>Purpose: Generate atmospheric forcing files using MPI.</p> <p>Tasks:</p> <ul> <li>Regrid NWM data to SCHISM mesh</li> <li>Interpolate forcing variables</li> <li>Generate SCHISM-compatible forcing files</li> </ul> <p>Runs On: Compute node (MPI parallel, inside Singularity)</p> <p>Outputs:</p> <pre><code>work_dir/\n\u2514\u2500\u2500 sflux/\n    \u251c\u2500\u2500 sflux_air_1.*.nc\n    \u251c\u2500\u2500 sflux_prc_1.*.nc\n    \u2514\u2500\u2500 sflux_rad_1.*.nc\n</code></pre>"},{"location":"user-guide/workflow-stages/#4-post_forcing","title":"4. post_forcing","text":"<p>Purpose: Post-process forcing data.</p> <p>Tasks:</p> <ul> <li>Validate generated forcing files</li> <li>Create forcing summary</li> <li>Clean up temporary files</li> </ul> <p>Runs On: Compute node (inside Singularity)</p>"},{"location":"user-guide/workflow-stages/#5-update_params","title":"5. update_params","text":"<p>Purpose: Generate SCHISM parameter file.</p> <p>Tasks:</p> <ul> <li>Create <code>param.nml</code> with simulation parameters</li> <li>Set time stepping configuration</li> <li>Configure output options</li> </ul> <p>Runs On: Compute node (inside Singularity)</p> <p>Outputs:</p> <pre><code>work_dir/\n\u2514\u2500\u2500 param.nml\n</code></pre>"},{"location":"user-guide/workflow-stages/#6-boundary_conditions","title":"6. boundary_conditions","text":"<p>Purpose: Generate boundary conditions from TPXO or STOFS.</p> <p>Tasks (TPXO):</p> <ul> <li>Extract tidal constituents at boundary nodes</li> <li>Generate harmonic boundary files</li> <li>Create <code>bctides.in</code> file</li> </ul> <p>Tasks (STOFS):</p> <ul> <li>Interpolate STOFS water levels to boundary</li> <li>Generate time-varying boundary files</li> <li>Create <code>elev2D.th.nc</code> file</li> </ul> <p>Runs On: Compute node (inside Singularity)</p>"},{"location":"user-guide/workflow-stages/#7-pre_schism","title":"7. pre_schism","text":"<p>Purpose: Final preparation before SCHISM execution.</p> <p>Tasks:</p> <ul> <li>Validate all input files present</li> <li>Set up symbolic links</li> <li>Configure MPI environment</li> </ul> <p>Runs On: Compute node (inside Singularity)</p>"},{"location":"user-guide/workflow-stages/#8-schism_run","title":"8. schism_run","text":"<p>Purpose: Execute the SCHISM model.</p> <p>Tasks:</p> <ul> <li>Run SCHISM with MPI</li> <li>Monitor progress</li> <li>Handle I/O scribes</li> </ul> <p>Runs On: Compute node (MPI parallel, inside Singularity)</p> <p>Configuration:</p> <ul> <li>Uses <code>nscribes</code> I/O processes from model config</li> <li>OpenMP threads configured via <code>omp_num_threads</code></li> <li>Total processes = <code>nodes * ntasks_per_node</code></li> </ul>"},{"location":"user-guide/workflow-stages/#9-post_schism","title":"9. post_schism","text":"<p>Purpose: Post-process SCHISM outputs.</p> <p>Tasks:</p> <ul> <li>Combine output files</li> <li>Generate statistics</li> <li>Create visualization-ready files</li> </ul> <p>Runs On: Compute node (inside Singularity)</p>"},{"location":"user-guide/workflow-stages/#sfincs-stage-details","title":"SFINCS Stage Details","text":""},{"location":"user-guide/workflow-stages/#1-download_1","title":"1. download","text":"<p>Same as SCHISM download stage. Downloads NWM meteorological forcing, streamflow, and STOFS water level data.</p>"},{"location":"user-guide/workflow-stages/#2-sfincs_symlinks","title":"2. sfincs_symlinks","text":"<p>Purpose: Create .nc symlinks for NWM data.</p> <p>Tasks:</p> <ul> <li>Create symlinks in the working directory pointing to downloaded NWM files</li> <li>Organize files by type (meteo, hydro)</li> </ul>"},{"location":"user-guide/workflow-stages/#3-sfincs_data_catalog","title":"3. sfincs_data_catalog","text":"<p>Purpose: Generate a HydroMT data catalog.</p> <p>Tasks:</p> <ul> <li>Build YAML data catalog for HydroMT-SFINCS</li> <li>Register NWM meteo, streamflow, and STOFS data sources</li> </ul>"},{"location":"user-guide/workflow-stages/#4-sfincs_init","title":"4. sfincs_init","text":"<p>Purpose: Initialise the SFINCS model from a pre-built template.</p> <p>Tasks:</p> <ul> <li>Load pre-built SFINCS model from <code>prebuilt_dir</code></li> <li>Set up model directory structure</li> </ul>"},{"location":"user-guide/workflow-stages/#5-sfincs_timing","title":"5. sfincs_timing","text":"<p>Purpose: Set SFINCS model timing.</p> <p>Tasks:</p> <ul> <li>Configure simulation start/end times</li> <li>Set output intervals</li> </ul>"},{"location":"user-guide/workflow-stages/#6-sfincs_forcing","title":"6. sfincs_forcing","text":"<p>Purpose: Add water level forcing.</p> <p>Tasks:</p> <ul> <li>Interpolate STOFS water levels to SFINCS boundary points</li> <li>Generate boundary forcing files</li> </ul>"},{"location":"user-guide/workflow-stages/#7-sfincs_obs","title":"7. sfincs_obs","text":"<p>Purpose: Add observation points.</p> <p>Tasks:</p> <ul> <li>Add tide gauge locations from <code>observation_points</code></li> <li>Configure observation output</li> </ul>"},{"location":"user-guide/workflow-stages/#8-sfincs_discharge","title":"8. sfincs_discharge","text":"<p>Purpose: Add discharge sources.</p> <p>Tasks:</p> <ul> <li>Add NWM streamflow discharge points from <code>discharge_locations_file</code></li> <li>Generate discharge forcing time series</li> </ul>"},{"location":"user-guide/workflow-stages/#9-sfincs_precip","title":"9. sfincs_precip","text":"<p>Purpose: Add precipitation forcing.</p> <p>Tasks:</p> <ul> <li>Add NWM precipitation data as spatially distributed forcing</li> </ul>"},{"location":"user-guide/workflow-stages/#10-sfincs_write","title":"10. sfincs_write","text":"<p>Purpose: Write the final SFINCS model.</p> <p>Tasks:</p> <ul> <li>Write all SFINCS input files (<code>sfincs.inp</code>, <code>sfincs.bnd</code>, etc.)</li> <li>Generate boundary and forcing NetCDF files</li> </ul>"},{"location":"user-guide/workflow-stages/#11-sfincs_run","title":"11. sfincs_run","text":"<p>Purpose: Execute the SFINCS model.</p> <p>Tasks:</p> <ul> <li>Run SFINCS inside Singularity container</li> <li>Uses single-node OpenMP parallelism (<code>omp_num_threads</code>)</li> </ul> <p>Runs On: Compute node (OpenMP, inside Singularity)</p>"},{"location":"user-guide/workflow-stages/#running-partial-workflows","title":"Running Partial Workflows","text":""},{"location":"user-guide/workflow-stages/#cli","title":"CLI","text":"<pre><code># SCHISM examples\ncoastal-calibration run config.yaml --stop-after download\ncoastal-calibration run config.yaml --start-from pre_forcing --stop-after post_forcing\ncoastal-calibration run config.yaml --start-from boundary_conditions\n\n# SFINCS examples\ncoastal-calibration run config.yaml --stop-after sfincs_write\ncoastal-calibration run config.yaml --start-from sfincs_run\n</code></pre>"},{"location":"user-guide/workflow-stages/#python-api","title":"Python API","text":"<pre><code>from coastal_calibration import CoastalCalibConfig, CoastalCalibRunner\n\nconfig = CoastalCalibConfig.from_yaml(\"config.yaml\")\nrunner = CoastalCalibRunner(config)\n\n# Run specific stages\nresult = runner.run(start_from=\"pre_forcing\", stop_after=\"post_forcing\")\n</code></pre>"},{"location":"user-guide/workflow-stages/#error-handling","title":"Error Handling","text":"<p>If a stage fails:</p> <ol> <li>The workflow stops at the failed stage</li> <li>Error details are logged</li> <li>Subsequent stages are not executed</li> <li>Exit code indicates failure</li> </ol> <p>To resume after fixing an issue:</p> <pre><code># Resume from the failed stage\ncoastal-calibration run config.yaml --start-from &lt;failed_stage&gt;\n</code></pre>"},{"location":"user-guide/workflow-stages/#stage-timing","title":"Stage Timing","text":"<p>When <code>enable_timing</code> is true in the monitoring configuration, stage durations are tracked and reported:</p> <pre><code>Stage timing:\n  download: 45.2s\n  pre_forcing: 12.3s\n  nwm_forcing: 234.5s\n  post_forcing: 8.7s\n  update_params: 2.1s\n  boundary_conditions: 156.8s\n  pre_schism: 5.4s\n  schism_run: 1823.6s\n  post_schism: 67.2s\nTotal: 2355.8s\n</code></pre>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#unreleased","title":"Unreleased","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>SFINCS coastal model workflow with full pipeline (download through sfincs_run)</li> <li>Polymorphic <code>ModelConfig</code> ABC with <code>SchismModelConfig</code> and <code>SfincsModelConfig</code>     concrete implementations</li> <li><code>MODEL_REGISTRY</code> for automatic model dispatch from YAML <code>model:</code> key</li> <li><code>--model</code> option for <code>init</code> and <code>stages</code> CLI commands</li> <li>Model-specific compute parameters (SCHISM: multi-node MPI; SFINCS: single-node OpenMP)</li> <li><code>${model}</code> variable in default path templates for model-aware directory naming</li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li><code>CoastalCalibConfig</code> now takes <code>model_config: ModelConfig</code> instead of separate     <code>model</code>, <code>mpi</code>, and <code>sfincs</code> parameters</li> <li><code>SlurmConfig</code> now contains only scheduling parameters (<code>job_name</code>, <code>partition</code>,     <code>time_limit</code>, <code>account</code>, <code>qos</code>, <code>user</code>); compute resources (<code>nodes</code>,     <code>ntasks_per_node</code>, <code>exclusive</code>) moved to <code>SchismModelConfig</code></li> <li>Default path templates use <code>${model}_</code> prefix instead of hardcoded <code>schism_</code></li> <li>Stage order and stage creation delegated to <code>ModelConfig</code> subclasses</li> <li>SFINCS field renames: <code>model_dir</code> -&gt; <code>prebuilt_dir</code>, <code>obs_points</code> -&gt;     <code>observation_points</code>, <code>obs_merge</code> -&gt; <code>merge_observations</code>, <code>src_locations</code> -&gt;     <code>discharge_locations_file</code>, <code>src_merge</code> -&gt; <code>merge_discharge</code>, <code>docker_tag</code> -&gt;     <code>container_tag</code>, <code>sif_path</code> -&gt; <code>container_image</code></li> </ul>"},{"location":"CHANGELOG/#removed","title":"Removed","text":"<ul> <li><code>MPIConfig</code> class (fields absorbed into <code>SchismModelConfig</code>)</li> </ul>"},{"location":"CHANGELOG/#010-2026-02-06","title":"0.1.0 - 2026-02-06","text":""},{"location":"CHANGELOG/#added_1","title":"Added","text":"<ul> <li>Initial release of NWM Coastal</li> <li>SCHISM coastal model workflow support</li> <li>YAML configuration with variable interpolation</li> <li>Configuration inheritance with <code>_base</code> field</li> <li>CLI commands: <code>init</code>, <code>validate</code>, <code>submit</code>, <code>run</code>, <code>stages</code></li> <li>Python API for programmatic workflow control</li> <li>Automatic data download from NWM and STOFS sources</li> <li>Support for TPXO and STOFS boundary conditions</li> <li>Support for four coastal domains: Hawaii, PRVI, Atlantic/Gulf, Pacific</li> <li>Interactive and non-interactive job submission modes</li> <li>Partial workflow execution with <code>--start-from</code> and <code>--stop-after</code></li> <li>Smart default paths with interpolation templates</li> <li>Comprehensive configuration validation</li> <li>MkDocs documentation with Material theme</li> </ul>"},{"location":"CHANGELOG/#supported-data-sources","title":"Supported Data Sources","text":"<ul> <li>NWM Retrospective 3.0 (1979-02-01 to 2023-01-31)</li> <li>NWM Analysis (2018-09-17 to present)</li> <li>STOFS water levels (2020-12-30 to present)</li> <li>GLOFS (Great Lakes OFS, 2005-09-30 to present)</li> <li>TPXO tidal model (local installation required)</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing","text":""},{"location":"CONTRIBUTING/#contributing-to-nwm-coastal","title":"Contributing to NWM Coastal","text":"<p>First off, thanks for taking the time to contribute! \u2764\ufe0f</p> <p>All types of contributions are encouraged and valued. See the Table of Contents for different ways to help and details about how this project handles them. Please make sure to read the relevant section before making your contribution. It will make it a lot easier for us maintainers and smooth out the experience for all involved. The community looks forward to your contributions. \ud83c\udf89</p> <p>And if you like the project, but just don't have time to contribute, that's fine. There are other easy ways to support the project and show your appreciation, which we would also be very happy about:</p> <ul> <li>Star the project</li> <li>Tweet about it</li> <li>Refer this project in your project's readme</li> <li>Mention the project at local meetups and tell your friends/colleagues</li> </ul>"},{"location":"CONTRIBUTING/#table-of-contents","title":"Table of Contents","text":"<ul> <li>I Have a Question</li> <li>I Want To Contribute<ul> <li>Reporting Bugs</li> <li>Suggesting Enhancements</li> <li>Your First Code Contribution</li> <li>Improving The Documentation</li> </ul> </li> </ul>"},{"location":"CONTRIBUTING/#i-have-a-question","title":"I Have a Question","text":"<p>If you want to ask a question, we assume that you have read the available Documentation.</p> <p>Before you ask a question, it is best to search for existing Issues that might help you. In case you have found a suitable issue and still need clarification, you can write your question in this issue. It is also advisable to search the internet for answers first.</p> <p>If you then still feel the need to ask a question and need clarification, we recommend the following:</p> <ul> <li>Open an Issue.</li> <li>Provide as much context as you can about what you're running into.</li> <li>Provide project and platform versions (<code>python</code>, <code>pixi</code>, etc), depending on what seems     relevant.</li> </ul> <p>We will then take care of the issue as soon as possible.</p>"},{"location":"CONTRIBUTING/#i-want-to-contribute","title":"I Want To Contribute","text":""},{"location":"CONTRIBUTING/#legal-notice","title":"Legal Notice","text":"<p>When contributing to this project, you must agree that you have authored 100% of the content, that you have the necessary rights to the content and that the content you contribute may be provided under the project license.</p>"},{"location":"CONTRIBUTING/#reporting-bugs","title":"Reporting Bugs","text":""},{"location":"CONTRIBUTING/#before-submitting-a-bug-report","title":"Before Submitting a Bug Report","text":"<p>A good bug report shouldn't leave others needing to chase you up for more information. Therefore, we ask you to investigate carefully, collect information and describe the issue in detail in your report. Please complete the following steps in advance to help us fix any potential bug as fast as possible.</p> <ul> <li>Make sure that you are using the latest version.</li> <li>Determine if your bug is really a bug and not an error on your side e.g. using     incompatible environment components/versions (Make sure that you have read the     documentation. If you are looking for     support, you might want to check this section).</li> <li>To see if other users have experienced (and potentially already solved) the same issue     you are having, check if there is not already a bug report existing for your bug or     error in the     bug tracker.</li> <li>Also make sure to search the internet (including Stack Overflow) to see if users     outside of the GitHub community have discussed the issue.</li> <li>Collect information about the bug:<ul> <li>Stack trace (Traceback)</li> <li>OS, Platform and Version (Windows, Linux, macOS, x86, ARM)</li> <li>Version of the interpreter, compiler, SDK, runtime environment, package manager,     depending on what seems relevant.</li> <li>Possibly your input and the output</li> <li>Can you reliably reproduce the issue? And can you also reproduce it with older     versions?</li> </ul> </li> </ul>"},{"location":"CONTRIBUTING/#how-do-i-submit-a-good-bug-report","title":"How Do I Submit a Good Bug Report?","text":"<p>You must never report security related issues, vulnerabilities or bugs including sensitive information to the issue tracker, or elsewhere in public. Instead sensitive bugs must be sent by email to the project maintainers.</p> <p>We use GitHub issues to track bugs and errors. If you run into an issue with the project:</p> <ul> <li>Open an Issue. (Since we can't be     sure at this point whether it is a bug or not, we ask you not to talk about a bug     yet and not to label the issue.)</li> <li>Explain the behavior you would expect and the actual behavior.</li> <li>Please provide as much context as possible and describe the reproduction steps that     someone else can follow to recreate the issue on their own. This usually includes     your code. For good bug reports you should isolate the problem and create a reduced     test case.</li> <li>Provide the information you collected in the previous section.</li> </ul> <p>Once it's filed:</p> <ul> <li>The project team will label the issue accordingly.</li> <li>A team member will try to reproduce the issue with your provided steps. If there are     no reproduction steps or no obvious way to reproduce the issue, the team will ask     you for those steps and mark the issue as <code>needs-repro</code>. Bugs with the <code>needs-repro</code>     tag will not be addressed until they are reproduced.</li> <li>If the team is able to reproduce the issue, it will be marked <code>needs-fix</code>, as well as     possibly other tags (such as <code>critical</code>), and the issue will be left to be     implemented by someone.</li> </ul>"},{"location":"CONTRIBUTING/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>This section guides you through submitting an enhancement suggestion for NWM Coastal, including completely new features and minor improvements to existing functionality. Following these guidelines will help maintainers and the community to understand your suggestion and find related suggestions.</p>"},{"location":"CONTRIBUTING/#before-submitting-an-enhancement","title":"Before Submitting an Enhancement","text":"<ul> <li>Make sure that you are using the latest version.</li> <li>Read the documentation carefully and find out     if the functionality is already covered, maybe by an individual configuration.</li> <li>Perform a search to see if the     enhancement has already been suggested. If it has, add a comment to the existing     issue instead of opening a new one.</li> <li>Find out whether your idea fits with the scope and aims of the project. It's up to you     to make a strong case to convince the project's developers of the merits of this     feature. Keep in mind that we want features that will be useful to the majority of     our users and not just a small subset. If you're just targeting a minority of users,     consider writing an add-on/plugin library.</li> </ul>"},{"location":"CONTRIBUTING/#how-do-i-submit-a-good-enhancement-suggestion","title":"How Do I Submit a Good Enhancement Suggestion?","text":"<p>Enhancement suggestions are tracked as GitHub issues.</p> <ul> <li>Use a clear and descriptive title for the issue to identify the suggestion.</li> <li>Provide a step-by-step description of the suggested enhancement in as many details     as possible.</li> <li>Describe the current behavior and explain which behavior you expected to see     instead and why. At this point you can also tell which alternatives do not work     for you.</li> <li>Explain why this enhancement would be useful to most NWM Coastal users. You may     also want to point out the other projects that solved it better and which could     serve as inspiration.</li> </ul>"},{"location":"CONTRIBUTING/#your-first-code-contribution","title":"Your First Code Contribution","text":"<p>Ready to contribute? Here's how to set up NWM Coastal for local development.</p> <ol> <li> <p>Fork the NWM Coastal repo through the GitHub website.</p> </li> <li> <p>Clone your fork locally and add the main <code>nwm-coastal</code> as the upstream remote:</p> <pre><code>git clone git@github.com:your_name_here/nwm-coastal.git\ngit remote add upstream git@github.com:NGWPC/nwm-coastal.git\n</code></pre> </li> <li> <p>Install Pixi then install the development environments:</p> <pre><code>cd nwm-coastal/\npixi install -e dev\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>git checkout -b bugfix-or-feature/name-of-your-bugfix-or-feature\ngit push\n</code></pre> </li> <li> <p>Now you can make your changes locally, make sure to add a description of the changes     to <code>CHANGELOG.md</code> file based on     Keep a Changelog and add extra tests, if     applicable, to <code>tests</code> folder. Also, make sure to give yourself credit by adding     your name at the end of the item(s) that you add in the history like this     <code>by [Your Name](https://github.com/your_handle)</code>. Then, fetch the latest updates from     the remote and resolve any merge conflicts:</p> <pre><code>git fetch upstream\ngit merge upstream/main\n</code></pre> </li> <li> <p>Then run linting, type checking, and tests:</p> <pre><code>pixi r lint\npixi r -e typecheck typecheck\npixi r -e test311 test\npixi r -e test314 test\n</code></pre> </li> <li> <p>If you are making breaking changes make sure to reflect them in the documentation,     <code>README.md</code>, and tests if necessary.</p> </li> <li> <p>Commit your changes and push your branch to GitHub following     Conventional Commits     specification. For example:</p> <pre><code>git add .\ngit commit -m \"feat: a detailed description of your changes.\"\ngit push origin name-of-your-branch\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"CONTRIBUTING/#improving-the-documentation","title":"Improving The Documentation","text":"<p>NWM Coastal could always use more documentation, whether as part of the official NWM Coastal docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"CONTRIBUTING/#attribution","title":"Attribution","text":"<p>This guide is based on the contributing-gen. Make your own!</p>"},{"location":"DESIGN/","title":"coastal-calibration: Design Documentation","text":""},{"location":"DESIGN/#overview","title":"Overview","text":"<p>The <code>coastal-calibration</code> Python package is a complete redesign and rewrite of the original bash-based SCHISM model calibration workflow. This document details the architectural improvements, design decisions, and substantial enhancements made over the original implementation.</p>"},{"location":"DESIGN/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Executive Summary</li> <li>Original Implementation Analysis</li> <li>New Architecture</li> <li>Key Design Decisions</li> <li>Substantial Improvements</li> <li>API Reference</li> <li>Potential Future Developments</li> </ol>"},{"location":"DESIGN/#executive-summary","title":"Executive Summary","text":"<p>The <code>coastal-calibration</code> package provides a modern Python interface for running SCHISM and SFINCS coastal model calibration workflows on HPC clusters. It wraps the existing operational workflow scripts with a clean, type-safe API while establishing the foundation for incremental improvements.</p>"},{"location":"DESIGN/#design-goals","title":"Design Goals","text":"<p>The primary objectives of this rewrite are to create a workflow that is:</p> <ol> <li>Intuitive and user-friendly - Simple YAML configuration, clear CLI commands,     helpful error messages</li> <li>Less prone to errors - Type-safe configuration, comprehensive validation,     structured logging</li> <li>Extensible - Polymorphic model architecture that supports SCHISM, SFINCS, and     future models via a common <code>ModelConfig</code> ABC</li> </ol>"},{"location":"DESIGN/#architectural-strategy","title":"Architectural Strategy","text":"<p>The package is designed with a stable public API that shields users from internal changes. This enables:</p> <ul> <li>Immediate usability - Users get a clean interface today, even while internals are     being improved</li> <li>Incremental rewriting - Embedded bash scripts can be replaced with pure Python one     stage at a time</li> <li>Safe evolution - Internal rewrites don't break user-facing code or configurations</li> </ul> <p>The long-term goal is to completely rewrite all embedded bash scripts in Python, but doing so incrementally allows the package to be useful immediately while that work proceeds.</p>"},{"location":"DESIGN/#key-features","title":"Key Features","text":"<ul> <li>Type-safe configuration via <code>dataclasses</code> with runtime validation</li> <li>Modular stage-based architecture for maintainability and extensibility</li> <li>Native Python datetime handling replacing fragile shell date arithmetic</li> <li>Async data downloading with built-in source validation</li> <li>CLI and programmatic APIs for both interactive and automated use</li> <li>SLURM job management with status monitoring</li> <li>Progress tracking and structured logging</li> <li>Configuration inheritance for DRY multi-run setups</li> <li>Smart default paths with variable interpolation</li> </ul>"},{"location":"DESIGN/#original-implementation-analysis","title":"Original Implementation Analysis","text":""},{"location":"DESIGN/#file-structure-20-scripts","title":"File Structure (20+ scripts)","text":"<pre><code>calib_org/\n\u251c\u2500\u2500 sing_run.bash                     # Main entry point (258 lines)\n\u251c\u2500\u2500 schism_calib.cfg                  # Configuration file\n\u251c\u2500\u2500 pre_nwm_forcing_coastal.bash      # Forcing preparation\n\u251c\u2500\u2500 post_nwm_forcing_coastal.bash     # Forcing post-processing\n\u251c\u2500\u2500 make_tpxo_ocean.bash              # TPXO boundary conditions\n\u251c\u2500\u2500 pre_regrid_stofs.bash             # STOFS pre-processing\n\u251c\u2500\u2500 post_regrid_stofs.bash            # STOFS post-processing\n\u251c\u2500\u2500 update_param.bash                 # Parameter file updates (249 lines)\n\u251c\u2500\u2500 pre_schism.bash                   # SCHISM input preparation\n\u251c\u2500\u2500 post_schism.bash                  # SCHISM output processing\n\u251c\u2500\u2500 merge_source_sink.bash            # Discharge file merging\n\u251c\u2500\u2500 initial_discharge.bash            # Initial discharge creation\n\u251c\u2500\u2500 combine_sink_source.bash          # Sink/source combination\n\u2514\u2500\u2500 run_sing_coastal_workflow_*.bash  # 8+ Singularity wrappers\n</code></pre>"},{"location":"DESIGN/#critical-issues-in-original-implementation","title":"Critical Issues in Original Implementation","text":""},{"location":"DESIGN/#1-fragile-date-arithmetic","title":"1. Fragile Date Arithmetic","text":"<p>The original workflow relied on external scripts for date calculations:</p> <pre><code># Original: External script calls for every date operation\nexport FORCING_END_DATE=$(${USHnwm}/utils/advance_time.sh $PDY$cyc $LENGTH_HRS)'00'\npdycyc=$(${USHnwm}/utils/advance_time.sh $PDY$cyc $hr)\n</code></pre> <p>This approach had several problems:</p> <ul> <li>Required external <code>advance_time.sh</code> and <code>advance_cymdh.pl</code> scripts</li> <li>Shell spawning overhead for each date operation</li> <li>Inconsistent handling of edge cases (leap years, month boundaries)</li> <li>No error handling for invalid dates</li> </ul>"},{"location":"DESIGN/#2-environment-variable-pitfalls","title":"2. Environment Variable Pitfalls","text":"<p>The original scripts passed dozens of environment variables between scripts:</p> <pre><code># Original configuration (schism_calib.cfg)\nexport STARTPDY=20230611\nexport STARTCYC=00\nexport FCST_LENGTH_HRS=3.0\nexport HOT_START_FILE=''\nexport USE_TPXO=\"NO\"\nexport COASTAL_DOMAIN=pacific\nexport METEO_SOURCE=NWM_RETRO\nexport COASTAL_WORK_DIR=/efs/schism_use_case/...\n\n# Plus 40+ more in sing_run.bash\nexport NGWPC_COASTAL_PARM_DIR=/ngen-test/coastal/ngwpc-coastal\nexport NGEN_APP_DIR=/ngen-app\nexport FCST_TIMESTEP_LENGTH_SECS=3600\nexport OTPSDIR=$NGEN_APP_DIR/OTPSnc\n# ... etc\n</code></pre> <p>Problems:</p> <ul> <li>No validation of variable values</li> <li>Easy to have typos that fail silently</li> <li>Difficult to track variable dependencies</li> <li>No documentation of which variables are required vs optional</li> </ul>"},{"location":"DESIGN/#3-string-based-domain-mapping","title":"3. String-Based Domain Mapping","text":"<pre><code># Original: Repeated in multiple files\ndeclare -A coastal_domain_to_inland_domain=( \\\n    [prvi]=\"domain_puertorico\" \\\n    [hawaii]=\"domain_hawaii\" \\\n    [atlgulf]=\"domain\" \\\n    [pacific]=\"domain\" )\n\ndeclare -A coastal_domain_to_nwm_domain=( \\\n    [prvi]=\"prvi\" \\\n    [hawaii]=\"hawaii\" \\\n    [atlgulf]=\"conus\" \\\n    [pacific]=\"conus\" )\n\ndeclare -A coastal_domain_to_geo_grid=( \\\n    [prvi]=\"geo_em_PRVI.nc\" \\\n    [hawaii]=\"geo_em_HI.nc\" \\\n    [atlgulf]=\"geo_em_CONUS.nc\" \\\n    [pacific]=\"geo_em_CONUS.nc\" )\n</code></pre> <p>Problems:</p> <ul> <li>Duplicated across multiple scripts</li> <li>No compile-time type checking</li> <li>Silent failures on unknown domains</li> </ul>"},{"location":"DESIGN/#4-no-data-download-integration","title":"4. No Data Download Integration","text":"<p>The original workflow required manual data downloading via a separate workflow. That workflow had no date validation, no source awareness, and no progress tracking.</p>"},{"location":"DESIGN/#5-minimal-error-handling","title":"5. Minimal Error Handling","text":"<pre><code># Original: Scripts would continue on failure\nsingularity exec -B $BINDINGS --pwd ${work_dir} $SIF_PATH \\\n    ./run_sing_coastal_workflow_pre_forcing_coastal.bash\n# No error check here\n\n${MPICOMMAND3} singularity exec -B $BINDINGS \\\n    --pwd ${work_dir} \\\n    $SIF_PATH \\\n    $CONDA_ENVS_PATH/$CONDA_ENV_NAME/bin/python \\\n    $USHnwm/wrf_hydro_workflow_dev/forcings/WrfHydroFECPP/workflow_driver.py\n# No error check here either\n</code></pre>"},{"location":"DESIGN/#new-architecture","title":"New Architecture","text":""},{"location":"DESIGN/#package-structure","title":"Package Structure","text":"<pre><code>src/coastal_calibration/\n\u251c\u2500\u2500 __init__.py                  # Package exports\n\u251c\u2500\u2500 cli.py                       # Command-line interface\n\u251c\u2500\u2500 runner.py                    # Main workflow orchestrator\n\u251c\u2500\u2500 downloader.py                # Async data downloading\n\u251c\u2500\u2500 scripts_path.py              # Script path management\n\u2502\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 schema.py                # YAML config dataclasses + ModelConfig ABC\n\u2502\n\u251c\u2500\u2500 stages/                      # Workflow stages\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base.py                  # Abstract WorkflowStage base class\n\u2502   \u251c\u2500\u2500 download.py              # Data download stage\n\u2502   \u251c\u2500\u2500 forcing.py               # NWM forcing stages\n\u2502   \u251c\u2500\u2500 boundary.py              # Boundary condition stages\n\u2502   \u251c\u2500\u2500 schism.py                # SCHISM execution stages\n\u2502   \u251c\u2500\u2500 sfincs.py                # SFINCS data catalog &amp; symlinks\n\u2502   \u2514\u2500\u2500 sfincs_build.py          # SFINCS model build stages (HydroMT)\n\u2502\n\u251c\u2500\u2500 scripts/                     # Embedded bash scripts\n\u2502   \u251c\u2500\u2500 tpxo_to_open_bnds_hgrid/ # TPXO Python utilities\n\u2502   \u2514\u2500\u2500 wrf_hydro_workflow_dev/  # WRF-Hydro forcing code\n\u2502\n\u2514\u2500\u2500 utils/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 logging.py               # Workflow monitoring\n    \u251c\u2500\u2500 slurm.py                 # SLURM job management\n    \u251c\u2500\u2500 time.py                  # Datetime utilities\n    \u2514\u2500\u2500 workflow.py              # Workflow helper functions\n</code></pre>"},{"location":"DESIGN/#core-components","title":"Core Components","text":""},{"location":"DESIGN/#1-configuration-system-configschemapy","title":"1. Configuration System (<code>config/schema.py</code>)","text":"<p>The new configuration system uses Python <code>dataclasses</code> with full type hints:</p> <pre><code>from dataclasses import dataclass\nfrom typing import Literal\n\nCoastalDomain = Literal[\"prvi\", \"hawaii\", \"atlgulf\", \"pacific\"]\nMeteoSource = Literal[\"nwm_retro\", \"nwm_ana\"]\nBoundarySource = Literal[\"tpxo\", \"stofs\"]\n\n\n@dataclass\nclass SimulationConfig:\n    \"\"\"Simulation time and domain configuration.\"\"\"\n\n    start_date: datetime\n    duration_hours: int\n    coastal_domain: CoastalDomain\n    meteo_source: MeteoSource\n    timestep_seconds: int = 3600\n\n    # Domain mappings as class variables\n    _INLAND_DOMAIN: ClassVar[dict[str, str]] = {\n        \"prvi\": \"domain_puertorico\",\n        \"hawaii\": \"domain_hawaii\",\n        \"atlgulf\": \"domain\",\n        \"pacific\": \"domain\",\n    }\n\n    @property\n    def start_pdy(self) -&gt; str:\n        \"\"\"Return start date as YYYYMMDD string.\"\"\"\n        return self.start_date.strftime(\"%Y%m%d\")\n\n    @property\n    def inland_domain(self) -&gt; str:\n        \"\"\"Inland domain directory name for this coastal domain.\"\"\"\n        return self._INLAND_DOMAIN[self.coastal_domain]\n</code></pre> <p>Benefits:</p> <ul> <li>Type safety: IDE autocompletion, static analysis with <code>pyright</code></li> <li>Self-documenting: Property names and docstrings explain purpose</li> <li>Validation: Runtime checks with helpful error messages</li> <li>DRY: Domain mappings defined once</li> </ul>"},{"location":"DESIGN/#2-yaml-configuration-with-inheritance","title":"2. YAML Configuration with Inheritance","text":"<pre><code># base.yaml - Shared defaults\nslurm:\n  partition: c5n-18xlarge\n\npaths:\n  nfs_mount: /ngen-test\n  singularity_image: /ngencerf-app/singularity/ngen-coastal.sif\n\n---\n# hawaii_run.yaml - Inherits from base\n_base: base.yaml\n\nsimulation:\n  start_date: '2023-06-11T00:00:00'\n  duration_hours: 24\n  coastal_domain: hawaii\n  meteo_source: nwm_retro\n\npaths:\n  work_dir: /ngen-test/coastal_runs/${simulation.coastal_domain}\n</code></pre> <p>Features:</p> <ul> <li>Variable interpolation: <code>${section.key}</code> syntax</li> <li>Inheritance: <code>_base</code> field for configuration reuse</li> <li>Deep merging: Override only what changes</li> <li>Smart defaults: Minimal configuration required</li> </ul> <p>When paths are not specified, they are automatically generated using templates that include the <code>${model}</code> variable for model-aware directory naming:</p> <pre><code>DEFAULT_WORK_DIR_TEMPLATE = (\n    \"/ngen-test/coastal/${slurm.user}/\"\n    \"${model}_${simulation.coastal_domain}_${boundary.source}_${simulation.meteo_source}/\"\n    \"${model}_${simulation.start_date}\"\n)\n\nDEFAULT_RAW_DOWNLOAD_DIR_TEMPLATE = (\n    \"/ngen-test/coastal/${slurm.user}/\"\n    \"${model}_${simulation.coastal_domain}_${boundary.source}_${simulation.meteo_source}/\"\n    \"raw_data\"\n)\n</code></pre> <pre><code>flowchart TD\n    base[base.yaml] --&gt; hawaii[hawaii_run.yaml]\n    base --&gt; pacific[pacific_run.yaml]\n    base --&gt; prvi[prvi_run.yaml]</code></pre>"},{"location":"DESIGN/#3-stage-based-workflow-architecture","title":"3. Stage-Based Workflow Architecture","text":"<p>The stage pipeline is model-specific. Each <code>ModelConfig</code> subclass defines its own <code>stage_order</code> and <code>create_stages()</code>.</p> <p>SCHISM pipeline:</p> <pre><code>flowchart TD\n    A[download] --&gt; B[pre_forcing]\n    B --&gt; C[nwm_forcing]\n    C --&gt; D[post_forcing]\n    D --&gt; E[update_params]\n    E --&gt; F[boundary_conditions]\n    F --&gt; G[pre_schism]\n    G --&gt; H[schism_run]\n    H --&gt; I[post_schism]</code></pre> <p>SFINCS pipeline:</p> <pre><code>flowchart TD\n    A[download] --&gt; B[sfincs_symlinks]\n    B --&gt; C[sfincs_data_catalog]\n    C --&gt; D[sfincs_init]\n    D --&gt; E[sfincs_timing]\n    E --&gt; F[sfincs_forcing]\n    F --&gt; G[sfincs_obs]\n    G --&gt; H[sfincs_discharge]\n    H --&gt; I[sfincs_precip]\n    I --&gt; J[sfincs_write]\n    J --&gt; K[sfincs_run]</code></pre> <p>Each stage is a Python class inheriting from <code>WorkflowStage</code>:</p> <pre><code>classDiagram\n    class WorkflowStage {\n        &lt;&lt;abstract&gt;&gt;\n        +run() dict\n        +validate() list\n    }\n    WorkflowStage &lt;|-- DownloadStage\n    WorkflowStage &lt;|-- ForcingStage\n    WorkflowStage &lt;|-- BoundaryStage\n    WorkflowStage &lt;|-- SCHISMStage\n    WorkflowStage &lt;|-- SFINCSBuildStage</code></pre> <p>The base class implementation:</p> <pre><code>class WorkflowStage(ABC):\n    \"\"\"Abstract base class for workflow stages.\"\"\"\n\n    name: str = \"base\"\n    description: str = \"Base workflow stage\"\n\n    def __init__(self, config: CoastalCalibConfig, monitor: WorkflowMonitor | None):\n        self.config = config\n        self.monitor = monitor\n\n    def build_environment(self) -&gt; dict[str, str]:\n        \"\"\"Build environment variables for the stage.\"\"\"\n        # Converts config to env vars for bash scripts\n        env = os.environ.copy()\n        env[\"STARTPDY\"] = self.config.simulation.start_pdy\n        env[\"STARTCYC\"] = self.config.simulation.start_cyc\n        # ... all precomputed, no shell date arithmetic needed\n        return env\n\n    def run_singularity_command(\n        self,\n        command: list[str],\n        use_mpi: bool = False,\n        mpi_tasks: int | None = None,\n    ) -&gt; subprocess.CompletedProcess[str]:\n        \"\"\"Run a command inside the Singularity container.\"\"\"\n        # Handles all Singularity setup, bindings, error checking\n        pass\n\n    @abstractmethod\n    def run(self) -&gt; dict[str, Any]:\n        \"\"\"Execute the stage and return results.\"\"\"\n        pass\n\n    def validate(self) -&gt; list[str]:\n        \"\"\"Validate stage prerequisites. Return list of errors.\"\"\"\n        return []\n</code></pre>"},{"location":"DESIGN/#4-workflow-runner-orchestration","title":"4. Workflow Runner Orchestration","text":"<pre><code>class CoastalCalibRunner:\n    \"\"\"Main workflow runner for coastal model calibration.\"\"\"\n\n    @property\n    def STAGE_ORDER(self) -&gt; list[str]:\n        \"\"\"Stage order is delegated to the model config.\"\"\"\n        return self.config.model_config.stage_order\n\n    def run(\n        self,\n        start_from: str | None = None,\n        stop_after: str | None = None,\n        dry_run: bool = False,\n    ) -&gt; WorkflowResult:\n        \"\"\"Execute the calibration workflow.\"\"\"\n        # Validation, stage sequencing, error handling, result collection\n        pass\n\n    def submit(self, wait: bool = False) -&gt; WorkflowResult:\n        \"\"\"Submit workflow as a SLURM job.\n\n        Parameters\n        ----------\n        wait : bool\n            If True, wait for job completion with status updates.\n            If False (default), return immediately after submission.\n        \"\"\"\n        pass\n</code></pre> <p>The <code>submit()</code> method execution flow is shown in the sequence diagram below:</p> <pre><code>sequenceDiagram\n    participant User\n    participant Runner\n    participant Slurm\n\n    User-&gt;&gt;Runner: submit(config)\n    Runner-&gt;&gt;Runner: validate()\n    Runner-&gt;&gt;Slurm: submit_job()\n    Slurm--&gt;&gt;Runner: job_id\n    Runner--&gt;&gt;User: WorkflowResult</code></pre>"},{"location":"DESIGN/#key-design-decisions","title":"Key Design Decisions","text":""},{"location":"DESIGN/#1-python-native-date-arithmetic","title":"1. Python-Native Date Arithmetic","text":"<p>Decision: Replace all bash/Perl date scripts with Python <code>datetime</code>.</p> <p>Rationale:</p> <ul> <li>Python's <code>datetime</code> and <code>timedelta</code> handle all edge cases correctly</li> <li>No external dependencies or shell spawning</li> <li>Type-safe with IDE support</li> </ul> <p>Implementation (<code>utils/time.py</code>):</p> <pre><code>_DATE_RE = re.compile(r\"^\\d{10}$\")\n\n\ndef _parse_date(date_string: str) -&gt; datetime:\n    \"\"\"Parse a YYYYMMDDHH string into a datetime, with strict validation.\"\"\"\n    if not isinstance(date_string, str) or not _DATE_RE.match(date_string):\n        raise ValueError(\n            f\"date_string must be exactly 10 digits in YYYYMMDDHH format, got {date_string!r}\"\n        )\n    return datetime.strptime(date_string, \"%Y%m%d%H\")\n\n\ndef advance_time(date_string: str, hours: int) -&gt; str:\n    \"\"\"Advance a date string by a specified number of hours.\n\n    Replaces advance_time.sh and advance_cymdh.pl with native Python.\n    Handles leap years, month boundaries, DST, etc.\n    \"\"\"\n    dt = _parse_date(date_string) + timedelta(hours=hours)\n    return dt.strftime(\"%Y%m%d%H\")\n</code></pre> <p>The module also consolidates <code>parse_datetime()</code> (flexible datetime parsing, previously duplicated in <code>config.schema</code> and <code>downloader</code>) and <code>iter_hours()</code> (hour-range iteration, previously in <code>downloader</code>).</p> <p>Impact: The <code>build_environment()</code> method precomputes shared date-derived values, then delegates model-specific env vars to <code>model_config.build_environment()</code>:</p> <pre><code># Shared dates computed once in Python, passed to bash scripts\nenv[\"FORCING_BEGIN_DATE\"] = f\"{pdycyc}00\"\nenv[\"FORCING_END_DATE\"] = forcing_end_dt.strftime(\"%Y%m%d%H00\")\nenv[\"END_DATETIME\"] = forcing_end_dt.strftime(\"%Y%m%d%H\")\n\n# Model-specific env vars (e.g., SCHISM_BEGIN_DATE, OMP_NUM_THREADS)\nenv = self.config.model_config.build_environment(env, self.config)\n</code></pre>"},{"location":"DESIGN/#2-integrated-data-downloading-with-validation","title":"2. Integrated Data Downloading with Validation","text":"<p>Decision: Build a comprehensive downloader with source awareness and date range validation.</p> <p>Rationale:</p> <ul> <li>Different data sources have different availability windows</li> <li>Users shouldn't waste time on downloads that will fail</li> <li>Async downloading is faster than sequential</li> </ul> <p>Implementation (<code>downloader.py</code>):</p> <pre><code>DATA_SOURCE_DATE_RANGES: dict[str, dict[str, DateRange]] = {\n    \"nwm_retro\": {\n        \"conus\": DateRange(\n            start=datetime(1979, 2, 1),\n            end=datetime(2023, 1, 31),\n            description=\"NWM Retrospective 3.0 (CONUS)\",\n        ),\n        \"hawaii\": DateRange(\n            start=datetime(1994, 1, 1),\n            end=datetime(2013, 12, 31),\n            description=\"NWM Retrospective 3.0 (Hawaii)\",\n        ),\n        # ...\n    },\n    \"stofs\": {\n        \"_default\": DateRange(\n            start=datetime(2020, 12, 30),\n            end=None,  # operational, no end date\n            description=\"STOFS (operational)\",\n        ),\n    },\n}\n\n\ndef download_data(\n    start_time: datetime,\n    end_time: datetime,\n    output_dir: Path,\n    domain: Domain,\n    meteo_source: MeteoSource = \"nwm_retro\",\n    coastal_source: CoastalSource = \"stofs\",\n) -&gt; DownloadResults:\n    \"\"\"Download with validation and progress tracking.\"\"\"\n    # Validates dates before downloading\n    errors = _validate_date_ranges(start, end, meteo_source, coastal_source, domain)\n    if errors:\n        raise ValueError(\"Date range validation failed:\\n\" + \"\\n\".join(errors))\n\n    # Uses tiny_retriever for async parallel downloads\n    download(urls, paths, timeout=timeout)\n</code></pre>"},{"location":"DESIGN/#3-configuration-over-convention","title":"3. Configuration Over Convention","text":"<p>Decision: Use explicit YAML configuration with sensible defaults.</p> <p>Rationale:</p> <ul> <li>Original relied on implicit conventions (file locations, naming patterns)</li> <li>Explicit configuration is self-documenting</li> <li>Easier to version control and share</li> </ul> <p>Example SCHISM configuration:</p> <pre><code>slurm:\n  job_name: coastal_calibration\n  partition: c5n-18xlarge\n\nsimulation:\n  start_date: '2023-06-11T00:00:00'\n  duration_hours: 24\n  coastal_domain: pacific\n  meteo_source: nwm_retro\n\nboundary:\n  source: tpxo  # or: source: stofs\n\npaths:\n  work_dir: /ngen-test/coastal_runs/my_run\n  raw_download_dir: /ngen-test/data/downloads\n\n# SCHISM compute parameters (model_config defaults to SchismModelConfig)\nmodel_config:\n  nodes: 2\n  ntasks_per_node: 18\n  nscribes: 2\n  omp_num_threads: 2\n\ndownload:\n  enabled: true\n  skip_existing: true\n</code></pre> <p>Example SFINCS configuration:</p> <pre><code>model: sfincs\n\nslurm:\n  job_name: sfincs_texas\n  user: your_username\n\nsimulation:\n  start_date: 2025-06-01\n  duration_hours: 168\n  coastal_domain: atlgulf\n  meteo_source: nwm_ana\n\nboundary:\n  source: stofs\n\nmodel_config:\n  prebuilt_dir: /path/to/texas/model\n  omp_num_threads: 36\n\ndownload:\n  enabled: true\n  skip_existing: true\n</code></pre>"},{"location":"DESIGN/#4-non-interactive-default-with-interactive-flag","title":"4. Non-Interactive Default with Interactive Flag","text":"<p>Decision: The <code>submit</code> command returns immediately by default, with an optional <code>--interactive</code> (<code>-i</code>) flag to wait for completion.</p> <p>Rationale:</p> <ul> <li>Matches standard <code>sbatch</code> behavior that users expect</li> <li>Allows users to submit jobs and continue working</li> <li>Interactive mode available when monitoring is desired</li> </ul> <p>CLI behavior:</p> <pre><code># Default: Submit and return immediately (like sbatch)\ncoastal-calibration submit config.yaml\n\n# Interactive: Wait for completion with status updates\ncoastal-calibration submit config.yaml --interactive\ncoastal-calibration submit config.yaml -i\n</code></pre>"},{"location":"DESIGN/#5-stable-public-api-with-incremental-internal-rewrite","title":"5. Stable Public API with Incremental Internal Rewrite","text":"<p>Decision: Establish a clean, stable public API while embedding existing scripts as a transitional measure.</p> <p>Rationale:</p> <p>The primary goal of this rewrite is to create an intuitive, user-friendly, and extensible workflow system. The existing bash and Python scripts are difficult to maintain and not performant. However, rewriting everything at once would:</p> <ul> <li>Delay delivery of a usable tool to users</li> <li>Risk introducing regressions without a baseline</li> <li>Require extensive testing before any release</li> </ul> <p>Strategy:</p> <p>The architecture deliberately separates public API from private implementation:</p> Layer Components Stability Public API <code>CoastalCalibConfig</code>, <code>CoastalCalibRunner</code>, CLI Stable Stage Interface <code>WorkflowStage.run()</code>, <code>.validate()</code>, <code>.build_environment()</code> Stable Private Implementation Bash scripts \u2192 Pure Python Evolving <p>This allows:</p> <ol> <li>Users get a stable interface today - The CLI and Python API won't change as     internals evolve</li> <li>Incremental rewriting - Each stage can be rewritten independently without     affecting others</li> <li>Testing baseline first - Establish test coverage against current behavior before     changes</li> <li>Performance optimization - Replace bash subprocess calls with native Python as     needed</li> </ol> <p>Current State:</p> <ul> <li>Package includes <code>scripts/</code> directory with embedded bash scripts</li> <li><code>WorkflowStage.run_singularity_command()</code> provides abstraction layer</li> <li>Python precomputes all environment variables, minimizing bash complexity</li> </ul> <p>Future Direction:</p> <ol> <li>Add comprehensive integration tests capturing current behavior</li> <li>Incrementally rewrite stages in pure Python (starting with simpler stages)</li> <li>Deprecate bash scripts as Python replacements are validated</li> <li>Optimize performance-critical paths (file I/O, data processing)</li> </ol>"},{"location":"DESIGN/#6-strict-type-checking-with-pyright","title":"6. Strict Type Checking with <code>pyright</code>","text":"<p>Decision: Use strict <code>pyright</code> mode for static type analysis.</p> <p>Rationale:</p> <ul> <li>Catches errors before runtime</li> <li>Enables IDE features (autocomplete, refactoring)</li> <li>Self-documents function signatures</li> </ul> <p>Configuration (<code>pyproject.toml</code>):</p> <pre><code>[tool.pyright]\ntypeCheckingMode = \"strict\"\ninclude = [\"src/coastal_calibration\"]\n</code></pre>"},{"location":"DESIGN/#substantial-improvements","title":"Substantial Improvements","text":""},{"location":"DESIGN/#1-error-handling-and-validation","title":"1. Error Handling and Validation","text":"Aspect Original New Configuration validation None 12+ checks in <code>CoastalCalibConfig.validate()</code> Stage validation None Each stage has <code>validate()</code> method Error messages Exit codes only Detailed, actionable messages Recovery Manual restart Partial workflow execution with <code>--start-from</code> <p>Validation examples:</p> <pre><code>def validate(self) -&gt; list[str]:\n    errors = []\n\n    # Shared validation\n    if self.simulation.duration_hours &lt;= 0:\n        errors.append(\"simulation.duration_hours must be positive\")\n\n    if (\n        self.boundary.source == \"stofs\"\n        and not self.boundary.stofs_file\n        and not self.download.enabled\n    ):\n        errors.append(\n            \"boundary.stofs_file required when using STOFS source and download is disabled\"\n        )\n\n    # Model-specific validation (delegated to ModelConfig subclass)\n    errors.extend(self.model_config.validate(self))\n\n    return errors\n</code></pre>"},{"location":"DESIGN/#2-progress-tracking-and-monitoring","title":"2. Progress Tracking and Monitoring","text":"<p>Original: No progress tracking, just log messages scattered in bash scripts.</p> <p>New: Structured monitoring with stage context:</p> <pre><code>class WorkflowMonitor:\n    \"\"\"Monitors and logs workflow execution progress.\"\"\"\n\n    def register_stages(self, stages: list[str]) -&gt; None:\n        \"\"\"Register stages for progress tracking.\"\"\"\n\n    @contextmanager\n    def stage_context(self, stage_name: str, description: str):\n        \"\"\"Context manager for stage execution with timing.\"\"\"\n        self.info(f\"Starting stage: {stage_name} - {description}\")\n        start = time.perf_counter()\n        try:\n            yield\n            duration = time.perf_counter() - start\n            self.info(f\"Completed stage: {stage_name} in {duration:.1f}s\")\n            self.progress[stage_name] = \"completed\"\n        except Exception as e:\n            self.progress[stage_name] = \"failed\"\n            raise\n\n    def save_progress(self, path: Path) -&gt; None:\n        \"\"\"Save progress to JSON for resumption.\"\"\"\n</code></pre>"},{"location":"DESIGN/#3-slurm-integration","title":"3. SLURM Integration","text":"<p>Original: Manual SLURM script writing, no job tracking.</p> <p>New: Full <code>SlurmManager</code> class:</p> <pre><code>class SlurmManager:\n    \"\"\"Manage SLURM job submission and monitoring.\"\"\"\n\n    def submit_job(self, script_path: Path) -&gt; str:\n        \"\"\"Submit and return job ID.\"\"\"\n\n    def get_job_status(self, job_id: str) -&gt; JobStatus:\n        \"\"\"Query job status from sacct/squeue.\"\"\"\n\n    def wait_for_job(self, job_id: str, poll_interval: int = 30) -&gt; JobStatus:\n        \"\"\"Block until job completes, logging state transitions.\"\"\"\n\n    def generate_job_script(self, output_path: Path) -&gt; Path:\n        \"\"\"Generate SLURM script from configuration.\"\"\"\n</code></pre>"},{"location":"DESIGN/#4-cli-with-multiple-entry-points","title":"4. CLI with Multiple Entry Points","text":"<pre><code># Initialize configuration for a domain\ncoastal-calibration init config.yaml --domain hawaii\n\n# Validate configuration\ncoastal-calibration validate config.yaml\n\n# Run directly (for testing)\ncoastal-calibration run config.yaml --dry-run\n\n# Submit to SLURM cluster\ncoastal-calibration submit config.yaml\n\n# Run partial workflow\ncoastal-calibration run config.yaml --start-from update_params --stop-after boundary_conditions\n\n# List available stages\ncoastal-calibration stages\n</code></pre>"},{"location":"DESIGN/#5-dual-api-cli-and-programmatic","title":"5. Dual API: CLI and Programmatic","text":"<pre><code># Python API\nfrom coastal_calibration import CoastalCalibConfig, CoastalCalibRunner\n\nconfig = CoastalCalibConfig.from_yaml(\"config.yaml\")\nrunner = CoastalCalibRunner(config)\n\n# Validate first\nerrors = runner.validate()\nif errors:\n    print(\"Validation failed:\", errors)\nelse:\n    result = runner.submit()\n    print(f\"Job {result.job_id}: {result.success}\")\n</code></pre>"},{"location":"DESIGN/#6-comprehensive-downloader","title":"6. Comprehensive Downloader","text":"Feature Original New Data sources Manual AWS CLI NWM Retro, NWM Ana, STOFS, GLOFS Date validation None Checks against known availability Parallel download None Async with <code>tiny_retriever</code> Skip existing None <code>skip_existing=True</code> option Progress tracking None Success/failure counts Domain awareness Manual Automatic URL building"},{"location":"DESIGN/#7-results-serialization","title":"7. Results Serialization","text":"<pre><code>@dataclass\nclass WorkflowResult:\n    success: bool\n    job_id: str | None\n    start_time: datetime\n    end_time: datetime | None\n    stages_completed: list[str]\n    stages_failed: list[str]\n    outputs: dict[str, Any]\n    errors: list[str]\n\n    @property\n    def duration_seconds(self) -&gt; float | None:\n        if self.end_time:\n            return (self.end_time - self.start_time).total_seconds()\n        return None\n\n    def save(self, path: Path) -&gt; None:\n        \"\"\"Save result to JSON for post-processing.\"\"\"\n</code></pre>"},{"location":"DESIGN/#api-reference","title":"API Reference","text":""},{"location":"DESIGN/#configuration-classes","title":"Configuration Classes","text":"Class Purpose <code>CoastalCalibConfig</code> Root configuration container <code>SlurmConfig</code> SLURM scheduling parameters <code>SimulationConfig</code> Time, domain, and source settings <code>BoundaryConfig</code> TPXO vs STOFS selection <code>PathConfig</code> All file and directory paths <code>ModelConfig</code> ABC for model-specific configuration <code>SchismModelConfig</code> SCHISM compute, MPI, and stage settings <code>SfincsModelConfig</code> SFINCS model paths, OpenMP, and stage settings <code>MonitoringConfig</code> Logging and progress tracking <code>DownloadConfig</code> Data download settings"},{"location":"DESIGN/#schism-workflow-stages","title":"SCHISM Workflow Stages","text":"Stage Class Description <code>download</code> <code>DownloadStage</code> Download NWM/STOFS/GLOFS data <code>pre_forcing</code> <code>PreForcingStage</code> Prepare forcing directories and symlinks <code>nwm_forcing</code> <code>NWMForcingStage</code> Run WRF-Hydro forcing engine (MPI) <code>post_forcing</code> <code>PostForcingStage</code> Post-process forcing files <code>update_params</code> <code>UpdateParamsStage</code> Generate SCHISM <code>param.nml</code> <code>boundary_conditions</code> <code>BoundaryConditionStage</code> TPXO or STOFS boundary generation <code>pre_schism</code> <code>PreSCHISMStage</code> Prepare SCHISM inputs <code>schism_run</code> <code>SCHISMRunStage</code> Execute <code>pschism</code> binary (MPI) <code>post_schism</code> <code>PostSCHISMStage</code> Validate and post-process outputs"},{"location":"DESIGN/#sfincs-workflow-stages","title":"SFINCS Workflow Stages","text":"Stage Class Description <code>download</code> <code>DownloadStage</code> Download NWM/STOFS data <code>sfincs_symlinks</code> <code>SFINCSSymlinksStage</code> Create <code>.nc</code> symlinks for NWM data <code>sfincs_data_catalog</code> <code>SFINCSDataCatalogStage</code> Generate HydroMT data catalog <code>sfincs_init</code> <code>SFINCSInitStage</code> Initialize SFINCS model <code>sfincs_timing</code> <code>SFINCSTimingStage</code> Set SFINCS timing <code>sfincs_forcing</code> <code>SFINCSForcingStage</code> Add water level forcing <code>sfincs_obs</code> <code>SFINCSObsStage</code> Add observation points <code>sfincs_discharge</code> <code>SFINCSDischargeStage</code> Add discharge sources <code>sfincs_precip</code> <code>SFINCSPrecipStage</code> Add precipitation forcing <code>sfincs_write</code> <code>SFINCSWriteStage</code> Write SFINCS model <code>sfincs_run</code> <code>SFINCSRunStage</code> Run SFINCS (Singularity/OpenMP)"},{"location":"DESIGN/#potential-future-developments","title":"Potential Future Developments","text":""},{"location":"DESIGN/#near-term-complete-python-rewrite","title":"Near-Term: Complete Python Rewrite","text":"<p>The highest priority is incrementally replacing embedded bash scripts with pure Python implementations:</p> <ol> <li> <p>Establish Testing Baseline</p> <ul> <li>Add integration tests that capture current workflow behavior</li> <li>Create reference outputs for regression testing</li> <li>Measure performance benchmarks for comparison</li> </ul> </li> <li> <p>Incremental Stage Rewriting</p> <ul> <li>Start with simpler stages (<code>pre_forcing</code>, <code>post_forcing</code>, <code>update_params</code>)</li> <li>Replace bash file operations with Python <code>pathlib</code> and <code>shutil</code></li> <li>Convert <code>sed</code>-based <code>param.nml</code> editing to Python template/parsing</li> <li>Rewrite forcing symlink creation in native Python</li> </ul> </li> <li> <p>Performance Optimization</p> <ul> <li>Profile current workflow to identify bottlenecks</li> <li>Replace subprocess calls with direct Python implementations</li> <li>Optimize file I/O patterns (batch operations, memory mapping)</li> <li>Consider parallel processing for independent operations</li> </ul> </li> <li> <p>Deprecate Bash Scripts</p> <ul> <li>Once Python replacements are validated, remove bash dependencies</li> <li>Simplify Singularity container requirements</li> <li>Reduce external tool dependencies</li> </ul> </li> </ol>"},{"location":"DESIGN/#medium-term-feature-expansion","title":"Medium-Term: Feature Expansion","text":"<ol> <li> <p>Hot Start Chain Automation</p> <ul> <li>Automatic hot-start file discovery</li> <li>Multi-run chaining for long simulations</li> </ul> </li> <li> <p>Ensemble Runs</p> <ul> <li>Multiple configurations from single base</li> <li>Parallel SLURM array jobs</li> </ul> </li> </ol>"},{"location":"DESIGN/#long-term-platform-evolution","title":"Long-Term: Platform Evolution","text":"<ol> <li> <p>Result Analysis Integration</p> <ul> <li>Post-run validation against observations</li> <li>Time series extraction and plotting</li> </ul> </li> <li> <p>Cloud-Native Deployment</p> <ul> <li>AWS Batch support</li> <li>Container-native execution (no Singularity)</li> </ul> </li> <li> <p>Multi-Model Coupling</p> <ul> <li>SCHISM + SFINCS workflows</li> <li>Nesting support</li> </ul> </li> </ol>"},{"location":"DESIGN/#conclusion","title":"Conclusion","text":"<p>The <code>coastal-calibration</code> package represents a substantial modernization of the original bash-based workflow:</p> Metric Original New Improvement Lines of bash ~2,500 ~500 (embedded) 80% reduction Lines of Python ~200 (scattered) ~4,000 (structured) Full rewrite Configuration Environment variables Typed YAML Type-safe Error handling Exit codes Exceptions + validation Comprehensive Testing None <code>pytest</code> + <code>pyright</code> CI-ready Documentation Comments only Docstrings + types Self-documenting Extensibility Copy &amp; modify scripts Inherit <code>WorkflowStage</code> Object-oriented Model support SCHISM only SCHISM + SFINCS Polymorphic <p>The architecture is designed for maintainability, extensibility, and correctness while supporting multiple coastal models (SCHISM and SFINCS) through a polymorphic <code>ModelConfig</code> ABC and preserving compatibility with the existing HPC infrastructure.</p>"}]}